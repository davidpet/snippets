*************************************************************************************
This document represents items that jumped out at me as needing to be studied for SQL interviews at a point in time.
Since in the future, different items would jump out at me based on the experience I have between now and then, it is only an artifact of this moment in time.
Going forward, I should review the actual notebooks, but this is so I can study up quickly at first.

Also, since there are a lot of dialect-specific things and advanced topics only a DBA
probably needs, it is not a very complete cheat sheet, at least this time around.
*************************************************************************************

[Syntax]
statements end with ;
	some systems allow DELIMITER command to specify a new one temporarily
	this is useful for things like stored procedures
	just remember to DELIMITER ; when done
-- this is a comment for the rest of the line
/* this is a multiline comment */

identifiers, operators, etc. are not case sensitive but built-in stuff is usually capitalized
	equality in strings is case sensitive by default

whitespace (including newline) is ignored - only a semicolon can end a statement
	if at end of query, missing semicolon ok
		but between two statements will cause issue

a common way to break is:
	SELECT
		name, age
	FROM
		employees
	ORDER BY
		age;

[Data Types]
INT
FLOAT
DECIMAL(m, n): fixed length before and after decimal point
CHAR(n): fixed length string (null not counted)
VARCHAR(n): variable length string (up to max) (null not counted)
BIT: boolean (0 or 1)
DATE: set to a string that has a proper date format (eg. 2012-01-01)
DATETIME: same but with timestamp after space
JSON: json string with object data

CAST(column1 AS DATE)
	in some systems, CONVERT() instead
DATE '2012-02-02'
	called type constructor

[Strings]
strings usually single-quoted (double-quoted not always even supported)
other types of quoting like [] and `` are system-dependent
double up quotes to escape them
+ for concat
N prefix before quote for unicode
double quotes can also be used to make identifiers CASE SENSITIVE
	by default they are not

SUBSTR(column1, start, stop)

UPPER(col)
LOWER(col)

LENGTH(strcol)
CONCAT()
REPLACE()
TRIM()
REPEAT()
REVERSE()

[Nullability]
all data types can have the value NULL if not present
NULL can be specified in a column spec (eg. in CREATE TABLE)

WHERE column1 IS NULL
WHERE column1 IS NOT NULL

COALESCE(column1, 0)
IFNULL(column1, 0) = same thing as COALESCE

[Variables]
for the duration of the script/session (like temporary tables)
	doesn't seem to work in jupyter

DECLARE @myVar INT:
SET @myVar = 10;

DECLARE @otherVar INT = 10;  -- both in 1 line
DECLARE @x INT, @y INT;  -- multiple in 1 line

PRINT 'The value is: ' + CAST(@myVar AS VARCHAR(10));

SELECT * FROM table WHERE id = @myVar;

[Macros]
??? TBD (Have notebook but haven't put here yet)
	parameterized views

[Select Statement]
overall order of clauses: [SELECT [DISTINCT]] [FROM] [JOIN] [WHERE] [ORDER BY] [LIMIT] [OFFSET] [GROUP BY] [HAVING]
actual execution order is: [FROM] [JOIN] [WHERE] [GROUP BY] [HAVING] [SELECT] [DISTINCT] [ORDER BY] [LIMIT/OFFSET]
	part of SELECT comes before GROUP BY though
	this is evidenced by the fact that you can use column aliases in a GROUP BY
	but GROUP BY also makes aggregates

[SELECT] = for defining what columns will be present in result
	SELECT *
		all columns
	SELECT column1, SUM(column2) AS total_column2, column3 AS col3
		SUM() is an aggregate
		others are AVG(), MAX(), MIN(), etc.
		they mostly make sense in terms of statements involving a GROUP BY (though can work standalone)
		COUNT(*) to count # of rows
		COUNT(col) to count # of non-null column values
		
		COUNT(name) can also be used to turn a whole result set into 1 row aggregated
			if no GROUP BY and no other columns listed
			if other non-aggregate columns, that's an error
		COUNT(DISTINCT name) can deduplicate
		eg. SELECT COUNT(name) - COUNT(DISTINCT name) AS duplicates FROM MyTable;
	AS lets you alias the column names in the results
		they are not usable in the WHERE but are in the ORDER BY and GROUP BY

	SELECT name, age, CASE 
				WHEN age < 30 THEN 'No Bonus'
				WHEN age > 30 THEN 'Bonus'
				ELSE 'Some bonus'
			  END AS bonus

	SELECT UPPER(name), age * 10

	SELECT column1 as "The First Column"
		a way to have multiple words (case sensitive)

	SELECT DISTINCT column1, column2
		deduplicates whole result set rows
		note that strings are case sensitive in this context
[FROM] = specifying what table to use
	can alias table names here which applies in rest of statement
		eg. FROM employees AS e
		then you can use e as the tablename in all other parts of the statement
[JOIN] = joining with another table
	eg. FROM employees INNER JOIN department ON employees.department_id = departments.id
	can alias the columns from the tables in the SELECT statement
	can filter with WHERE clause (using the table names from the join)

	INNER JOIN = all combinations matching the ON
	LEFT JOIN = all rows from left, matched with right where applicable
		LEFT OUTER JOIN = synonymous
	RIGHT JOIN = all rows from right, matched with left where applicable
		RIGHT OUTER JOIN = synonymous
	FULL OUTER JOIN = all rows from both tables, matched when applicable
	CROSS JOIN = all combos of rows from both tables (no ON)
	
	self join = a term for using the same table as both sides of the join
	
[WHERE] = which rows to include (no aliases)
	eg. col1 = 25
	eg. col2 <> 25
	eg. col3 = 'hi'
	eg. age <= 30 AND salary > 5500
	eg. salary BETWEEN 5500 AND 6500
	eg. name LIKE '%mi%'
		each % is a wildcard'
	eg. salary IS NOT NULL

	can use table name inc. alias as prefix if needed
		but not column aliases in this part yet
	columns don't have to be explicitly mentioned (or even included) in the SELECT

	for json, use ->> operator to dereference column as a field from the JSON
		for inserting a new row, need to use a json string

	NOTE: you can leave off table name if not ambiguous
ORDER BY column ASC
	or DESC
	default is ASC

	ORDER BY column1 ASC, column2 DESC
		for 2 level ordering

	without ORDER BY, order of rows is not guaranteed
		even if you test it and it appears to always be insertion order, the engine could suddenly do it differently in production context
LIMIT n
	only get first n rows
OFFSET n
	skip first n rows
GROUP BY column1, column2
	generally you select column1 and column2 in the SELECT
	then you can aggregate other columns with MAX, AVG, etc.
	each combo of column1 and column2 is a row
HAVING
	a condition on aggregates of groups (eg. SUM())
	the resulting filtration happens on whole groups from group by

subqueries grouped with () can be used for single values if aggregate
	WHERE EXISTS () if a subquery returns at least 1 row

Full Examples:
	SELECT * FROM Book; /* all rows, all columns */

	SELECT * FROM Book WHERE price > 100.00 ORDER BY title;

	SELECT col1 AS column1, col2 AS column2, SUM(col3) AS column3_sum FROM employees
		WHERE column1 > 10  ORDER BY column3_sum GROUP BY column1, column2;

	SELECT e.id, e.name, o.id AS orderId, o.product FROM employees AS e INNER JOIN orders AS o ON e.id = o.customer_id

[Subqueries and Derived Tables]
grouping a part of a query with () makes a subquery
	subqueries execute before the top query so that the results can be used
	essentially it makes a temporary table in memory that is then thrown away when the statement ends
	think of it like a pipeline, not a for each
		by default, subqueries run as a discrete step, not on each row
a subquery that returns a single column of a single row (eg. an aggregate) can be used to provide a single value (eg. duplicated to to all rows in outer query)
	a subquery can also be used this way in WHERE to get a condition value to filter against
it is possible to reference a column from the outer query in a subquery, which makes it a CORRELATED SUBQUERY
	this is very expensive in that it will then do the subquery FOR EACH ROW (usually to be avoided - use join instead)

a subquery in the FROM part creates a DERIVED TABLE
	this is just a temporary table that goes away when the statement is done (executed once before outer query)
	some engines require you to alias the derived table or they will throw an error (and some don't)
		eg. SELECT subquery.x, subquery.y FROM (SELECT * FROM sometable) subquery ORDER BY subquery.x;
			the alias goes after the subquery and can be used as a table name in the rest of the query

derived tables can participate in joins as well (the usual rules apply - just a little harder to understand)
	easier to understand if you don't use correlated subqueries and remember it runs once at the beginning to make a temporary table

[Window Functions]
SELECT id, name, age, ROW_NUMBER() OVER (PARTITION BY age ORDER BY id) AS row
    FROM employees
    ORDER BY age, row;

window function applies to 1 column and is structured like this:
	FUNCTION_CALL() OVER (PARTITION BY col1 ORDER BY col2) AS column_name
unlike GROUP BY, windowing functions do not collapse rows!
	the PARTITION BY determines how a window is defined
	the function iterates within each window in the order given by the ORDER BY
		this does not affect the final output order
		if the final order is compatible, the engine should be able to optimize instead of penalize you for double looping
you can ommit PARTITION BY to have the whole table be 1 window (eg. if want to apply the functions to all rows returned)
	keep in mind windowing is applied after WHERE and before things like ORDER BY and GROUP BY
you can technically ommit ORDER BY, but then you lose control of the order for applying window functions
	if just doing an aggregate like COUNT() that's fine
	eg. SELECT age, COUNT(*) OVER () AS count ...

Specific Window Functions:
	ROW_NUMBER()
		1-based index in order of ORDER BY
	RANK()
		like ROW_NUMBER() but for repeated values of the ORDER BY field, repeats indices and skips to make gaps
	DENSE_RANK()
		like RANK() but doesn't leave gaps in the indexing

Aggregates as Window Functions:
	COUNT(), AVG(), etc. can be used as window functions too
		eg. COUNT(*) OVER ()
	if no ORDER BY is present, they calculate the value for the whole window and repeat it
		otherwise, they do a CUMULATIVE RUNNING VALUE in order

Window Aliases:
	SELECT 
        id, name, age,
        ROW_NUMBER() OVER age_window AS row,
        RANK() OVER age_window AS rank
    FROM employees
    WINDOW age_window AS (PARTITION BY age ORDER BY id)
    ORDER BY age, row

	WINDOW clause defines alias as the part that comes after OVER normally
		then you can use that in the column specs instead of repeating it over and over
		must come after WHERE in the statement
		note that unlike normally, the left part of AS here is the name
	
[Union, Intersect, Except]
SELECT * FROM table1 INTERSECT SELECT * FROM table2;
	combines two WHOLE QUERIES (including the where, etc.)
	
INTERSECT = rows that are identical in results from both tables
UNION = deduplicated rows from results from either table
EXCEPT = result rows in first and not in 2nd

[Iteration and Lists]
arrays with [] syntax do exist in some implementations, but it's not universal
	often worked around with strings, JSON, table normalization, etc.

SELECT * FROM employees WHERE office_id IN (1, 2, 3);
	IN is shorthand for using OR and =
		but more optimized by the engine
	office_id IN (1, 2, 3) becomes office_id = 1 OR office_id = 2 OR office_id = 3
	the (1, 2, 3) here is not some kind of list or set data type but is just shorthand for that bigger condition
	if you were passing in a list from another language, you could format it into the string sent to the SQL engine
		eg. with python f-strings
SELECT * FROM employees WHERE office_id IN (SELECT id FROM offices);
	IN can take a subquery instead of hardcoded values
	this is useful if you want to pass the values as a table instead of in the query itself
IN can be thought of as doing an outer loop on rows matching the condition (as opossed to all rows)
	then you can further tweak the "iteration" by using window functions and subqueries to do filtering within groups of rows
	the final result can then be returned as a flat table with a composite sort (that the consuming script can easily break by)
	you can also return JSON, but the handling of JSON depends on the engine, so it gets complicated
note that you may have to use a subquery due to WHERE not having access to column aliases (eg. from window functions)
	but the engine can optimize this kind of subquery very well, much better than complex joins, so you don't need to worry

This example gets a flat list (sorted by author and then reverse sorted by article ID) of the last 2 (or 0 or 1 as applicable) articles for each author:
	SELECT
		author_id,
		article_id,
		article_name
	FROM (
		SELECT
			author_id,
			article_id,
			article_name,
			ROW_NUMBER() OVER (PARTITION BY author_id ORDER BY article_id DESC) AS row
		FROM
			articles
	)
	WHERE
		row <= 2
	ORDER BY
		author_id, article_id DESC;

[Database Creation]
CREATE DATABASE mydatabase;
USE DATABASE mydatabase;
DROP DATABASE mydatabase;

[Table Creation]
-- can leave out the OR REPLACE
-- query involving Customers table still needs an ON with the 2 fields being compared with =
CREATE OR REPLACE TABLE employees (
    id INT PRIMARY KEY, -- primary key (automatically indexed as UNIQUE)
    name VARCHAR(50),
    age INT UNIQUE, -- putting UNIQUE here means the column is indexed as each row having unique value
    salary DECIMAL(10,2) NULL, -- nullable column
    customer_id INT, -- this will be used as foreign key
    FOREIGN KEY (customer_id) REFERENCES Customers(customer_id) -- link foreign key to other table's primary key
);

CREATE TABLE IF NOT EXISTS employees (...);

CREATE TABLE employees 2 AS SELECT * FROM employees; -- cloning a table

DESCRIBE employees;

[Table Deletion]
DROP TABLE employees;
DROP TABLE IF EXISTS employees;

[Inserting Rows]
INSERT INTO employees (id, name, age, salary)
VALUES (1, 'John Doe', 30, 5000.00),
       (2, 'Jane Smith', 25, NULL),
       (3, 'Mike Johnson', 35, 8000.00),
       (4, 'Sarah Williams', 40, NULL);

Note that even though you are specifying the column names, the order still has to be right

[Updating Rows]
UPDATE employees SET salary = 75000.00 WHERE id = 2;

[Deleting Rows]
DELETE FROM employees WHERE id = 1;

TRUNCATE TABLE employees; -- clearing

[Changing Table Spec]
ALTER TABLE, ALTER COLUMN, etc.

[Temporary Table]
CREATE TEMPORARY TABLE mytable AS SELECT * FROM employees;
	this table will die after this session ends
	you can also DROP TABLE it explicitly

[Normalization/Denormalization]
having a lot of smaller tables with foreign keys to avoid redundancy is known as Normalization
having a bigger table with rows that have a lot of duplicated fields (as if JOINed) and a few columns different is Denormalization
generally you have one or the other depending on the needs of the system
Denormalization is faster for larger queries while Normalization uses less space

[Indexing]
primary key automatically indexed as unique
can also specify unique index in the CREATE TABLE as above
attempting to insert a redundant value is an ERROR

you can also index retroactively:
CREATE INDEX idx_name ON employees (name); -- not unique
CREATE UNIQUE INDEX idx_id ON employees (id);
CREATE INDEX idx_age_salary ON employees (age, salary); -- combination of columns indexed
CREATE UNIQUE INDEX idx_name_age ON employees (name, age);

you are indexing the existing columns but you have an index name that you can DROP INDEX on later for instance

indices are transparent to the queryer
	they have a performance hit on inserting new items but make queries faster
	excessive indexing will use extra storage and slow down insert/update/delete operations

How indices actually work:
	1. You can think of a composite index as __appending the columns__ in the order specified in the index.
    	-  eg. if you index on __(column1, column2, column3)__, then the indexed value is the concatenating of those 3 columns in that order
	2. Internally, the index is basically a __binary search tree__, like a sorted map or set in Java.
		- it is O(logn) lookup, not O(1) (even for simple things like getting a single item by ID)
		- hash-based O(1) indexing is uncommon in relational databases (more common in NoSQL)
	3. If an operation doesn't benefit from the indexing, then it just becomes a __sequential search__ (O(n))
	4. An operation that searches or sorts can benefit from the indexing if you __use the columns in order__ with no other columns interveaning
		- eg. if the index has __(column1, column2, column3)__, then you can search or sort by column1+column2, column1+column2+column3, or just column1, but not column2+column3 or just column2 or column3.
	5. This order applies across the whole query in certain places
		- eg. you might use column1 and column2 in the WHERE clause and column3 in the ORDER BY clause which comes later
	6. It is ok to have a composite index that uses a subset of a __composite primary key__ (indexing is independent of primary keys)
	7. You can have multiple indices combined in various ways to support the queries you need
		- but you might end up needing multiple denormalized tables or something if you can't arrange the phases efficiently
	8. You can use the SQL `EXPLAIN` command to see how it queries the index for a given query

[Foreign Keys]
since you still have to do an ON statement, foreign keys don't appear to do much on the surface
they have some less obvious benefits:
	prevent inserting row with invalid foreign key
	some systems automatically delete obsolete rows of the foreign table when delete rows of the parent table

[Views]
A view acts like a table for querying and lives in the DB, but it is just a query that gets executed when needed
	this makes it dynamically responsive to changes in the tables it queries against

CREATE OR REPLACE VIEW myview AS SELECT * FROM employees WHERE age < 30;
	the part after AS becomes what's stored in the DB as the query to execute dynamically
DROP VIEW IF EXISTS myview;
	delete the view
SELECT * FROM myview;
	query just like any table

[Built-in Functions]
** many others mentioned in [Strings] section **
CURRENT_DATE
CURRENT_TIME
CURRENT_TIMESTAMP
EXTRACT(YEAR FROM col)

[User-Defined Functions and Stored Procedures]
user-defined functions are stored in the DB to return a value
stored procedures are stored in the DB to execute actions (eg. maintenance)
syntax of both is rather ugly - not included here because can't run in Jupiter
you can also have triggers and transactions (w/ commit and rollback)

[ACID]
** the syntax here is hypothetical as JupySQL doesn't allow any of it **

Atomicity = transactions
Consistency = schema constraints
Isolation = transactions
Durability = once transaction over, the result is permanent

BEGIN TRANSACTION;

-- do multiple reads and updates

IF ERRORS <> 0 ROLLBACK; -- end transaction with nothing changed
IF ERRORS = 0 COMMIT;  -- end transaction with everything atomically committed

up to the DB system and config what granularity of timestamps, locking, etc. used
	and what kind of consistency, parallelism, etc. is desired
	eg. could lock rows, or whole tables, etc.

sidenote: languages like Clojure can do OCC with help of CAS (compare and swap)

APIs for programming languages often have their own transaction calls instead of having to do it in SQL

[APIs]
think of entity framework
an entity's type determines what table it belongs in already (because a table is a list of entities of a type)
you create an instance of the entity and save it (eg. with session object that is connected to DB)
session can also start and commit/rollback transactions
a session can have a query method to take a SQL query and give back, for instance, a list of entities
	in Java you need to pass a class object to let it know what kind of object to create from it
remember to rollback transaction if an exception is thrown

Java = Hibernate
C# = Entity framework
Python = SQLAlchemy

[Security of Connection String]
if stored locally, must be encrypted
have to think about how to store the decryption key though
external solutions from Google and AWS can help make it more secure
easier to make secure on a web app than on a desktop app (because can choose what's exposed to clients)
