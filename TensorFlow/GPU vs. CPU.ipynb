{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6307ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def make_tensor():\n",
    "    return tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39b29eb6",
   "metadata": {},
   "source": [
    "## GPU Default\n",
    "\n",
    "On my systems, GPU is configured, so tensors are created on **GPU by default**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541001da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = make_tensor()\n",
    "t.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b1aea89",
   "metadata": {},
   "source": [
    "## Manual Override to CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c41e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "t.device  # Note that once you exit the context, the tensor remains on the CPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41eaae5c",
   "metadata": {},
   "source": [
    "## Operations Stay on CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18afacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "t = t**2\n",
    "t.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdb38a5d",
   "metadata": {},
   "source": [
    "## Operations Themselves Don't Move to GPU (even in GPU context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ee9371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "with tf.device('/GPU:0'):\n",
    "    print(t.device)\n",
    "    t = t**2  # The **2 operation makes a new tensor but it is still CPU despite the context\n",
    "    print(t.device)\n",
    "print(t.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31c30d6e",
   "metadata": {},
   "source": [
    "## Moving to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1198b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "with tf.device('/GPU:0'):\n",
    "    t = tf.identity(\n",
    "        t\n",
    "    )  # This makes a new tensor without doing operations, so it successfully moves to GPU\n",
    "    print(t.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fcfb0ba",
   "metadata": {},
   "source": [
    "## Mixed Device Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5654c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "with tf.device('/GPU:0'):\n",
    "    u = make_tensor()\n",
    "v = t + u\n",
    "print(t.device)  # Original stays on the CPU\n",
    "print(u.device)  # Original stays on the GPU\n",
    "print(\n",
    "    v.device\n",
    ")  # Result is in GPU because that's preferred (presumably t had to be copied there)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ef7413",
   "metadata": {},
   "source": [
    "## Python Code Against GPU Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0516ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    t = make_tensor()\n",
    "t = t + 5\n",
    "t.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eefebd2",
   "metadata": {},
   "source": [
    "## Keras Conversion to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45ee7c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    t = make_tensor()\n",
    "    input_layer = tf.keras.Input(shape=t.shape)\n",
    "    output_layer = tf.keras.layers.Dense(5)(input_layer)\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    print(model(t).device)\n",
    "print(model(t).device\n",
    "     )  # Only the context of the model call matters (and defaults to GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
