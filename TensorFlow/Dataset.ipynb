{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5ab3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_dataset():\n",
    "    t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(t)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def print_batches(dataset):\n",
    "    for batch in dataset:\n",
    "        print('--BATCH--')\n",
    "        print(batch)\n",
    "        print()\n",
    "        \n",
    "def first_batch(dataset):\n",
    "    return next(iter(dataset.take(1)))\n",
    "\n",
    "def count_batches(dataset):\n",
    "    return dataset.reduce(0, lambda x,_: x + 1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cefdbd",
   "metadata": {},
   "source": [
    "## Create from Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c35be6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # 1st dimension is automatically treated as batch size\n",
    "dataset = tf.data.Dataset.from_tensor_slices(t)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9e571",
   "metadata": {},
   "source": [
    "## Iterate\n",
    "\n",
    "The 1st dimension is the sample dimension and the __default batch size is 1__.\n",
    "\n",
    "A dataset is an __iterator over batches__.  A batch is a subset of the original tensor in the row direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953f116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset()\n",
    "for batch in dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a7f90",
   "metadata": {},
   "source": [
    "## Batch Size\n",
    "\n",
    "You can __override the default__.\n",
    "\n",
    "If using a dataset, you __don't need to specify in model.fit()__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4d868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([[7 8 9]], shape=(1, 3), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().batch(2)\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a06f5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this doesn't work\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().batch(2).batch(3)  # You can't override the batch size a 2nd time\n",
    "try:\n",
    "    print_batches(dataset)\n",
    "except:\n",
    "    print('this doesn\\'t work')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d352d",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "You can use this to __count batches__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a3e62250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dataset().reduce(0, lambda x,_: x + 1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faac78",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "\n",
    "Notice that the __whole thing__ was shuffled even though the batch size was 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1e53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().shuffle(buffer_size=3, seed=42)\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668899d",
   "metadata": {},
   "source": [
    "## Splitting/Slicing\n",
    "\n",
    "The count accepted by these methods is in terms of __batches__ rather than rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77a3e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().take(2)  # Only include the first 2 batches (head)\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e587eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().take(2).shuffle(buffer_size=2, seed=42)\n",
    "print_batches(dataset)  # You won't see 7, 8, 9 here because we did take(2) before shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93e1b957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().skip(1) # tail\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5032ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().shuffle(buffer_size=3, seed=42)\n",
    "train,val = dataset.take(2), dataset.skip(2)\n",
    "print_batches(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dd2c1",
   "metadata": {},
   "source": [
    "## CPU\n",
    "\n",
    "Unlike normal tensors, datasets __default to CPU__ even if you have a GPU available.  The model will eventually move it into GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4b69d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset()\n",
    "print(first_batch(dataset).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ef935",
   "metadata": {},
   "source": [
    "## Prefetch\n",
    "\n",
    "If you were using a dataset other than tensor here (eg. CSV), you would be able to use prefetch to have batches load into memory while the model is working on the current batch.\n",
    "\n",
    "This is normally done at the __end of the pipeline__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "027508c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().prefetch(tf.data.AUTOTUNE) # Special value means automatically tune the # of batches\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d624f1",
   "metadata": {},
   "source": [
    "## Map\n",
    "\n",
    "Function runs on each batch and returns a new batch, which is generally a transformed version of the old batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05986c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([ 8 10 12], shape=(3,), dtype=int32)\n",
      "\n",
      "--BATCH--\n",
      "tf.Tensor([14 16 18], shape=(3,), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().map(lambda batch: batch*2)\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c218a1",
   "metadata": {},
   "source": [
    "## Ground-Truth (Label) Values\n",
    "\n",
    "__model.fit()__ expects dataset batches to be tuples of x,y.  This means you leave off the y argument of model.fit for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bdea8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 5], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 8], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=9>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().map(lambda batch: (batch[:-1], batch[-1]))\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302de64b",
   "metadata": {},
   "source": [
    "Tuples automatically unwrapped to __multiple args__ of function passed to map.  If the labels are present as a 2nd tuple item, you need to pass them back in the map function or they will be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89360a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 5], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 8], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=9>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset().map(lambda batch: (batch[:-1], batch[-1]))\n",
    "dataset = dataset.map(lambda batch,label: (batch,label))\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc29575",
   "metadata": {},
   "source": [
    "You may need something like this if you want to use the same transformation function for validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97dd3713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 4], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 8, 10], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n",
      "\n",
      "--BATCH--\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([14, 16], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=9>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transform_batch(batch, label=None):\n",
    "    batch = batch * 2\n",
    "    if label == None:\n",
    "        return batch\n",
    "    else:\n",
    "        return (batch, label)\n",
    "    \n",
    "dataset = make_dataset().map(lambda batch: (batch[:-1], batch[-1]))\n",
    "dataset = dataset.map(transform_batch)\n",
    "\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506df0ac",
   "metadata": {},
   "source": [
    "## Tuples of Tensors\n",
    "\n",
    "This is the manual way to create a structure like the __ground truth label__ scenario above.  The tuple remains a tuple with parallel batching inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25325a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>, <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[9, 8, 7],\n",
      "       [6, 5, 4],\n",
      "       [3, 2, 1]], dtype=int32)>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "u = tf.constant([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((t, u)).batch(3)\n",
    "\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b478c",
   "metadata": {},
   "source": [
    "## Lists of Tensors\n",
    "\n",
    "Although this looks similar to the tuple case, the __behavior is different__.  Instead of getting a list of tensors in the data stream, you get a __single tensor__ where the first dimension is the one selecting between the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5382927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[9 8 7]\n",
      "  [6 5 4]\n",
      "  [3 2 1]]], shape=(2, 3, 3), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "u = tf.constant([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([t, u]).batch(3)\n",
    "\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b9df1",
   "metadata": {},
   "source": [
    "## Dictionary of Tensors\n",
    "\n",
    "Zip (instead of from_tensor_slices) accepts a dictionary of tensors and makes a dataset out of it.  This is the same format used by csv datasets.  The results will be weird if you don't make the batch sizes of the constituent datasets the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d237d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "{'a': <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>, 'b': <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.zip({'a': make_dataset().batch(3), 'b': make_dataset().batch(3)})\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9668a2",
   "metadata": {},
   "source": [
    "This is how to manually do what csv datasets does when a label is involved.  Strangely, it uses from_tensor_slices instead of zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a49a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "({'a': <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>, 'b': <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>}, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.zip(({'a': make_dataset().batch(3), 'b': make_dataset().batch(3)}, tf.data.Dataset.from_tensor_slices(tf.constant(tf.zeros(shape=3))).batch(3)))\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abf1e8",
   "metadata": {},
   "source": [
    "You can also use map to transform between dataset formats.  In this example, we go from a dictionary dataset to a tuple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfbae55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>, <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.zip({'a': make_dataset().batch(3), 'b': make_dataset().batch(3)})\n",
    "dataset = dataset.map(lambda x: x.values())\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cf32d",
   "metadata": {},
   "source": [
    "## Generator Dataset\n",
    "\n",
    "Each yielded item counts as __1 sample__ and then batch size is applied to samples.  You can specify the format of the data (without batch size dimension) in output_signature.  A batch dimension is automatically added as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aa217135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--BATCH--\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_generator():\n",
    "    yield tf.constant([[1, 2], [3, 4]])\n",
    "    yield tf.constant([[5, 6], [7, 8]])\n",
    "dataset = tf.data.Dataset.from_generator(make_generator, output_signature=tf.TensorSpec(shape=(2,2,), dtype=tf.int32)).batch(2)\n",
    "print_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aab6d",
   "metadata": {},
   "source": [
    "## Dataset from CSV File\n",
    "\n",
    "The only __required__ arguments are the __filename and batch size__.  There are a lot of other arguments to control how CSV files are interpretted.  In this case, the defaults worked well for this CSV file.  The __first line__ contains __column names__.\n",
    "\n",
    "The data is __streamed from disk__ instead of being loaded all at once.\n",
    "\n",
    "By default, data is __prefetched__ with __autotune__ but that can be configured.\n",
    "\n",
    "By default, entries are __shuffled__ for each epoch.  You can configure this behavior including the seed and buffer size.\n",
    "\n",
    "You can provide the __label_name__ parameter to extract a label column and make it a tuple dataset automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fb6dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PassengerId': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([230], dtype=int32)>, 'Survived': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, 'Pclass': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>, 'Name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Lefebre, Miss. Mathilde'], dtype=object)>, 'Sex': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'female'], dtype=object)>, 'Age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'SibSp': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>, 'Parch': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, 'Ticket': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4133'], dtype=object)>, 'Fare': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.4667], dtype=float32)>, 'Cabin': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>, 'Embarked': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'S'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('titanic.csv', batch_size=1)\n",
    "print(dict(first_batch(dataset)))  #  convert to dict for print purposes because ordereddict doesn't display nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6071d6",
   "metadata": {},
   "source": [
    "The __num_epochs__ argument causes it to repeat the whole dataset transparently (as if the extra copies were in the original data).  If not specified, the default is to __repeat forever__ this way.\n",
    "\n",
    "If you want to control the epochs from the model instead, set num_epochs=1 and then the model will __reiterate for each epoch__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1374a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in dataset: 891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('titanic.csv', batch_size=1, num_epochs=1)\n",
    "print('Rows in dataset: ' + str(count_batches(dataset)))\n",
    "dataset = tf.data.experimental.make_csv_dataset('titanic.csv', batch_size=1, num_epochs=2)\n",
    "count_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05428716",
   "metadata": {},
   "source": [
    "The results of using __.batch()__ on a csv dataset __don't make sense__.  Just use the parameter in make_csv_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5d2e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('titanic.csv', batch_size=2, num_epochs=1).batch(1) # Don't do this\n",
    "count_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae216a5e",
   "metadata": {},
   "source": [
    "By default, every time you iterate (__another epoch__ at the model level), the rows are __reshuffled__, which you would normally want in order to prevent order dependence in your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "092504e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('titanic.csv', batch_size=891, num_epochs=1, shuffle_seed=42)\n",
    "print(first_batch(dataset)['PassengerId'][0].numpy())\n",
    "print(first_batch(dataset)['PassengerId'][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129f7d4",
   "metadata": {},
   "source": [
    "## Dataset from Pandas Dataframe\n",
    "\n",
    "Keep in mind this will __not stream__.  But if you're ok with loading it all into (CPU) RAM ahead of time, you get the benefit of being able to do pandas transformations.\n",
    "\n",
    "An interesting difference from directly from CSV above is you get a bunch of scalar tensors instead of rank 1 tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cdf7fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'PassengerId': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'Pclass': <tf.Tensor: shape=(), dtype=int32, numpy=3>, 'Name': <tf.Tensor: shape=(), dtype=string, numpy=b'Braund, Mr. Owen Harris'>, 'Sex': <tf.Tensor: shape=(), dtype=string, numpy=b'male'>, 'Age': <tf.Tensor: shape=(), dtype=float32, numpy=22.0>, 'SibSp': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'Parch': <tf.Tensor: shape=(), dtype=int32, numpy=0>, 'Ticket': <tf.Tensor: shape=(), dtype=string, numpy=b'A/5 21171'>, 'Fare': <tf.Tensor: shape=(), dtype=float32, numpy=7.25>, 'Cabin': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'Embarked': <tf.Tensor: shape=(), dtype=string, numpy=b'S'>}, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('titanic.csv').replace(np.nan, {'Embarked': '', 'Cabin': ''})  # Clean the data so TF will take it\n",
    "x = df.drop(columns=['Survived']).to_dict('list')  # Get dictionary data\n",
    "y = df['Survived'].tolist() # Get labels\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "print(first_batch(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be5388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
