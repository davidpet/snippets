{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0d4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41d7981",
   "metadata": {},
   "source": [
    "## Scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8127b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "0.0\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "scalar = tf.zeros(shape=())\n",
    "print(scalar)\n",
    "print(scalar + scalar)\n",
    "print(scalar + 1)\n",
    "\n",
    "print(scalar.numpy())  # Get back the actual scalar value\n",
    "\n",
    "print(tf.reshape(scalar,\n",
    "                 shape=(1)).numpy())  # Can reshape into a tensor of 1 element\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3729e34b",
   "metadata": {},
   "source": [
    "## Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea71ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vector = tf.zeros(shape=(5))\n",
    "print(vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c5a2a1d",
   "metadata": {},
   "source": [
    "## Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0104c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "matrix = tf.zeros(shape=(5, 5))\n",
    "print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "817bcd2c",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "Basically, single indices tend to make that dimension go away while slices tend to maintain the original form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348ccd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Column Index: (5,)\n",
      "Multi-Column Index: (5, 1)\n",
      "Single Row Index: (5,)\n",
      "Multi-Row Index: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "matrix = tf.zeros(shape=(5, 5))\n",
    "print(f'Single Column Index: {matrix[:,1].shape}')\n",
    "print(f'Multi-Column Index: {matrix[:,1:2].shape}')\n",
    "print(f'Single Row Index: {matrix[1].shape}'\n",
    "     )  # Notice it's the same shape as single column index\n",
    "print(f'Multi-Row Index: {matrix[1:2].shape}'\n",
    "     )  # Notice it's the transpose of single column index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31a92202",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "\n",
    "Although in certain places in TF (eg. dataset), shapes can be dictionaries, this is not generally allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd3edca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nope\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dictionary = tf.zeros(shape={'field1': (5, 5), 'field2': ()})\n",
    "except:\n",
    "    print('nope')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76bfaa9b",
   "metadata": {},
   "source": [
    "If you wanted to do it in the general case, this is the best you can do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f19cff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field1': <tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]], dtype=float32)>, 'field2': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>}\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'field1': tf.zeros(shape=(5, 5)), 'field2': tf.zeros(shape=())}\n",
    "print(dictionary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c737c65",
   "metadata": {},
   "source": [
    "## Dictionary in Keras\n",
    "\n",
    "Note the use of **input_shape** instead of **input**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7484c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nope\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.keras.layers.Input(shape={\n",
    "        'field1': (5, 5),\n",
    "        'field2': ()\n",
    "    })  # This is also a no-go\n",
    "except:\n",
    "    print('nope')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4298d15f",
   "metadata": {},
   "source": [
    "You can use a dictionary to inform the constructor of tf.keras.Model how to unwrap its input (a dictionary here).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad89edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field1': (None, 5, 5), 'field2': (None,)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(5, 5))\n",
    "input2 = tf.keras.layers.Input(shape=())\n",
    "inputs = {\n",
    "    'field1': input1,\n",
    "    'field2': input2\n",
    "}  # Only used for the final step (use input1 and input2 in graph)\n",
    "outputs = tf.keras.layers.Dense(3)(\n",
    "    input1\n",
    ")  # Technically input2 is being ignored in this network but just example\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=inputs, outputs=outputs\n",
    ")  # The dictionary is not a tensor but is an outer structure for tensors\n",
    "print(\n",
    "    model.input_shape\n",
    ")  # The shape looks like the one you specified but a batch dimension is added to all tensors\n",
    "\n",
    "model({\n",
    "    'field1': tf.zeros(shape=(2, 5, 5)),\n",
    "    'field2': tf.zeros(shape=(2))\n",
    "})  # The model accepts a straight dictionary of tensors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f92b3f37",
   "metadata": {},
   "source": [
    "## Multiple Tensor Inputs/Outputs in Keras\n",
    "\n",
    "This is useful if you need to pass in tensors of **different forms** without using ragged tensors.\n",
    "\n",
    "List of tensors in, list of tensors out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c57d6be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [(None, 5), (None, 3)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(5))\n",
    "input2 = tf.keras.layers.Input(shape=(3))\n",
    "inputs = [input1, input2]\n",
    "output1 = tf.keras.layers.Dense(2)(input1)\n",
    "output2 = tf.keras.layers.Dense(4)(input2)\n",
    "outputs = [output1, output2]\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(f'Input Shape: {model.input_shape}')\n",
    "\n",
    "t = tf.zeros(shape=(10, 5))  # Batch size 10\n",
    "u = tf.zeros(shape=(10, 3))\n",
    "\n",
    "model([t, u])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a80cb9c1",
   "metadata": {},
   "source": [
    "## Single Tensor Column Routing\n",
    "\n",
    "The ChatGPT-approved version uses tf.keras.layers.Lambda, which is not recommended because if you save the model, it saves environment-specific bytecode.\n",
    "\n",
    "A key thing to note here is that your layer can **return a tuple** and each items in the tuple is a graph node.\n",
    "\n",
    "NOTE: I did it this way to demonstrate layer classes, but you could just do tensor operations too (which I didn't know when I made this cell).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "47fc9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (None, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SplitLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (\n",
    "            inputs[:, :5], inputs[:, 5:]\n",
    "        )  # You could skip the whole class and just do left,right = (inputs....\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(8))  # Take all 8 columns in input tensor\n",
    "left, right = SplitLayer()(inputs)  # Split the columns\n",
    "dense1 = tf.keras.layers.Dense(2, name='dense_2')(left)\n",
    "dense2 = tf.keras.layers.Dense(4, name='dense_4')(right)\n",
    "\n",
    "output = tf.keras.layers.Concatenate(axis=-1, name='concat')([dense1, dense2])\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "print(f'Input Shape: {model.input_shape}')\n",
    "\n",
    "t = tf.zeros(shape=(10, 8))  # Batch size 10\n",
    "\n",
    "model(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d47a4579",
   "metadata": {},
   "source": [
    "## Dictionary to Tensor Routing\n",
    "\n",
    "In this example, we take an input dictionary with a one-hot feature and a scalar feature, and return a more typical matrix tensor compatible with dense layers, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d350af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=array([[1., 0., 0., 0., 0., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(\n",
    "    shape=(5),\n",
    "    name='input1')  # Each item in batch is a 5 item array (eg. one-hot)\n",
    "input2 = tf.keras.layers.Input(shape=(),\n",
    "                               name='input2')  # Each item in batch is a scalar\n",
    "inputs = {\n",
    "    'oh': input1,\n",
    "    'scal': input2\n",
    "}  # Input is a dictionary of batched tensors\n",
    "\n",
    "output = tf.keras.layers.Concatenate(\n",
    "    axis=-1, name='concat')([input1, tf.expand_dims(input2, axis=-1)])\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name='bla')\n",
    "\n",
    "model({\n",
    "    'oh': tf.constant([[1, 0, 0, 0, 0]]),\n",
    "    'scal': tf.constant([6])\n",
    "})  # Note that passing naked arrays fails here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbf104d4",
   "metadata": {},
   "source": [
    "## Batch Size\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73cd11fd",
   "metadata": {},
   "source": [
    "Layers are constructed without the batch dimension in the shape, but **after construction** they have it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73e8f5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (None, 5)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(\n",
    "    shape=(5))  ## Constructed without batch dimension\n",
    "print(f'Input Shape: {input1.shape}')  ## Batch dimension added in front"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d10f40",
   "metadata": {},
   "source": [
    "For a **dictionary**, the batch size is added to **each field separately**.\n",
    "Also note that you have to **call with a batch**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7fee175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(5, 5))  # No batch size in here\n",
    "input2 = tf.keras.layers.Input(shape=())\n",
    "inputs = {'field1': input1, 'field2': input2}\n",
    "outputs = tf.keras.layers.Dense(3)(input1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model({\n",
    "    'field1': tf.zeros(shape=(2, 5, 5)),\n",
    "    'field2': tf.zeros(shape=(2))\n",
    "})  # Batch added to each field\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a11217",
   "metadata": {},
   "source": [
    "For a **list of tensors**, the batch size is added to **each entry separately**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c853a854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(5))\n",
    "input2 = tf.keras.layers.Input(shape=(3))\n",
    "inputs = [input1, input2]\n",
    "output1 = tf.keras.layers.Dense(2)(input1)\n",
    "output2 = tf.keras.layers.Dense(4)(input2)\n",
    "outputs = [output1, output2]\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "t = tf.zeros(shape=(10, 5))  # Batch size 10\n",
    "u = tf.zeros(shape=(10, 3))\n",
    "\n",
    "model([t, u])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf5c62d",
   "metadata": {},
   "source": [
    "Also note that if you use a **layer class** the **call()** method will take batched tensors(s) as well. Basically once you instantiate a layer, everything has batches from that point on.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb492ec6",
   "metadata": {},
   "source": [
    "## Graph Mode\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4f29156",
   "metadata": {},
   "source": [
    "A layer can be called on a concrete tensor for **eager mode** evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16859a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-1.9751551,  0.2966845]], dtype=float32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(2)(tf.constant([[1, 2]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3973db1e",
   "metadata": {},
   "source": [
    "The same layer can also be called on a graph node for **graph mode** evaluation. Note that what you get back is still a tensor, but of a different type (**KerasTensor**). You can examine properties such as **shape**. Note that any dimension that is not known at the time the graph is being built can be **None** (for instance the batch size dimension). You can **pass None yourself** for dimensions when applicable too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba534b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='dense_63/BiasAdd:0', description=\"created by layer 'dense_63'\")\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(5))  # Graph mode tensor\n",
    "t = tf.keras.layers.Dense(2)(input_layer)\n",
    "print(t)  # Another tensor\n",
    "print(t.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "191357e8",
   "metadata": {},
   "source": [
    "You can perform **arbitrary tensor operations** in a graph too and that will get included in the graph. It won't disrupt anything such as GPU execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fca344c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 1.        4.        8.999998 16.       24.999998]], shape=(1, 5), dtype=float32)\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(5))  # Graph mode tensor\n",
    "output_layer = input_layer**2  # Could also be something like tf.reshape\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "result = model(tf.constant([[1, 2, 3, 4, 5]]))\n",
    "print(result)\n",
    "print(result.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e4ab2ec",
   "metadata": {},
   "source": [
    "You can **compile a function** to a graph (eg. custom helper code inside a training loop) using @tf.function.\n",
    "\n",
    "The example here doesn't work as I expected, but usually in coursera courses tf.function is used for a custom **training loop step** so that each training step runs faster (as an optimized graph instead of python).\n",
    "\n",
    "The tracing/compilation happens on the **first call** so if only called once, it's worthless to do. Also, it's only worthwhile if there are a lot of small operations. It won't help at all if all you're doing is convolutions.\n",
    "\n",
    "NOTE: this would not be needed for a function that creates your model because operaitons on graph mode tensors already result in a graph, and it's only happening once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "977861b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def make_graph_tensor():\n",
    "    return tf.constant([1, 2, 3])\n",
    "\n",
    "\n",
    "print(make_graph_tensor())\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(5))  # Graph mode tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac7389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
