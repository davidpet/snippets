{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4ba252",
   "metadata": {},
   "source": [
    "# Simple Test Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a69cdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_something(self):\n",
    "        self.assertEqual(1, 1)\n",
    "    def test_something_else(self):\n",
    "        self.assertEqual(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73115564",
   "metadata": {},
   "source": [
    "# Simple Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6699f9",
   "metadata": {},
   "source": [
    "## Specific File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "39d944ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder/my_tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a626dbc",
   "metadata": {},
   "source": [
    "## Module\n",
    "\n",
    "Note the following:\n",
    "\n",
    "- no slashes (dots instead)\n",
    "- no file extension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3a95a9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884d39d",
   "metadata": {},
   "source": [
    "## Specific Class\n",
    "\n",
    "To do this, you have to load as a module instead of a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab6acb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests.MyTests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb94f18",
   "metadata": {},
   "source": [
    "## Specific Method\n",
    "\n",
    "To do this, you have to:\n",
    "\n",
    "- load as a module\n",
    "- specify the classname as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9651a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests.MyTests.test_something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a14bf",
   "metadata": {},
   "source": [
    "# Printing from Within Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "964fcda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/mytests_with_output.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/mytests_with_output.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_something(self):\n",
    "        x = 0\n",
    "        \n",
    "        print(f'ATTENTION: Value of x before test is {x}')\n",
    "        self.assertEqual(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "674548b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "ATTENTION: Value of x before test is 0\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.mytests_with_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a733c",
   "metadata": {},
   "source": [
    "# Test Class Members\n",
    "\n",
    "You will often want common helper methods and variables to capture side effects in tests. It is safe to put these on the test class as long as they are **instance members** and not static members. Each test method gets executed **in its own class instance**, so as long as nothing is static, they won't interfere with each other.\n",
    "\n",
    "Also note that to create instance variables, you need to **override \\_\\_init\\_\\_** correctly as shown.\n",
    "\n",
    "Also note that the test framework uses the **test\\_ prefix** to tell which methods are tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e48d6ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/mytests_with_members.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/mytests_with_members.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "# Pretend this was imported from an API we will test.\n",
    "class Transmitter:\n",
    "    def transmit_x(self, fn):\n",
    "        fn(10)\n",
    "        \n",
    "class MyTests(unittest.TestCase):\n",
    "    def __init__(self, methodName='runTest'):\n",
    "        super().__init__(methodName)\n",
    "        \n",
    "        # Instance variable\n",
    "        self.captured_x = None\n",
    "        \n",
    "    # Helper method\n",
    "    def capture_x(self, x):\n",
    "        self.captured_x = x\n",
    "        \n",
    "    def test_1(self):\n",
    "        transmitter = Transmitter()\n",
    "        \n",
    "        transmitter.transmit_x(self.capture_x)\n",
    "        \n",
    "        self.assertEqual(self.captured_x, 10)\n",
    "        \n",
    "    # If they ran in the same instance, this would fail.\n",
    "    def test_2(self):\n",
    "        self.assertIsNone(self.captured_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3ed00085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.mytests_with_members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54276fd9",
   "metadata": {},
   "source": [
    "# Yoda Conditions\n",
    "\n",
    "Some people prefer to write `self.assertEqual(10, x)` instead of `self.assertEqual(x, 10)`. For a lot of asserts like assertEqual, it doesn't matter. However, some asserts, especially the ones in **tensorflow.test.TestCase**, actually make less sense.\n",
    "\n",
    "Overall, pay attention to the **param names** of assert methods to make sure you're using them as intended. For instance, if you used the non-yoda version for tensorflow.test.TestCase.assertAllEqual, the output would say \"expected x but got 10\" which would be confusing when debugging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b55b1",
   "metadata": {},
   "source": [
    "# Some Useful Asserts\n",
    "\n",
    "There are a lot of asserts you can use in the TestCase class. Here are just a few examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13c79c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_asserts.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_asserts.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_int(self):\n",
    "        x = 0\n",
    "        self.assertEqual(x, 0)\n",
    "        \n",
    "    def test_string(self):\n",
    "        x = 'hi'\n",
    "        self.assertEqual(x, 'hi')\n",
    "        \n",
    "    def test_none(self):\n",
    "        x = None\n",
    "        self.assertIsNone(x)\n",
    "        \n",
    "    def test_negation(self):\n",
    "        self.assertIsNotNone(10)\n",
    "        ## Use of Is is not consistent in the asserts.\n",
    "        self.assertNotEqual(10, 11)\n",
    "        \n",
    "    def test_list(self):\n",
    "        x = [1, 2, 3]\n",
    "        self.assertListEqual(x, [1, 2, 3])\n",
    "        \n",
    "    def test_dict(self):\n",
    "        x = {'a': 'hi'}\n",
    "        self.assertDictEqual(x, {'a': 'hi'})\n",
    "        \n",
    "    def test_type(self):\n",
    "        x = 5\n",
    "        self.assertIsInstance(x, int)\n",
    "        \n",
    "    def test_reference(self):\n",
    "        x = [1, 2, 3]\n",
    "        self.assertIs(x, x)\n",
    "        self.assertIsNot(x, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94676a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "........\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_asserts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef5850",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "To assert between tensors and numpy arrays, python arrays, etc. you just need to derive from a **different base** to get the extra assert methods.\n",
    "\n",
    "Unfortunately, you will also see the multitude of irrelevant warnings your TF prints if you haven't turned them off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55d10a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_tf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_tf.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class MyTests(tf.test.TestCase):\n",
    "    def test_tensor(self):\n",
    "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "        # This is a case where you have to do Yoda conditions.\n",
    "        self.assertAllEqual([[1, 2, 3], [4, 5, 6]], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44dd672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-05-19 11:45:44.668931: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 11:45:45.258768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "s2023-05-19 11:45:46.019127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.044091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.044182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.050740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.050838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.050902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.654403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.654562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.654597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-19 11:45:46.654667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-19 11:45:46.654725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8859 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.801s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928dc29",
   "metadata": {},
   "source": [
    "# Mocking\n",
    "\n",
    "The mocking library is very big and complex. Only a few examples are shown here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46039c3f",
   "metadata": {},
   "source": [
    "## Mocking print()\n",
    "\n",
    "Note below that prints that happen within the `with` block do not get printed to the console but instead get appended to our array. Once the block is over, printing goes to the console again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ced03bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_mocking.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_mocking.py\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "\n",
    "def my_print(val):\n",
    "    print(val)\n",
    "    \n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_my_print(self):\n",
    "        printed = []\n",
    "        with patch('builtins.print', new = lambda *args,**_: printed.append(args[0])):\n",
    "            my_print(10)\n",
    "            my_print('hi')\n",
    "        print('ATTENTION: printed after mocking ended')\n",
    "        self.assertListEqual(printed, [10, 'hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ab23731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "ATTENTION: printed after mocking ended\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_mocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35883d71",
   "metadata": {},
   "source": [
    "## Mocking Other Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e88d29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_mocking_general.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_mocking_general.py\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "\n",
    "from os import path\n",
    "    \n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_dirname(self):\n",
    "        captured = []\n",
    "        # Need to use fully qualified name of symbol instead of how you imported it.\n",
    "        with patch('os.path.dirname', new = lambda file: captured.append(file)):\n",
    "            path.dirname('some file')\n",
    "        # This one won't append.\n",
    "        path.dirname(__file__)\n",
    "        self.assertListEqual(captured, ['some file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cbee8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_mocking_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7f32f",
   "metadata": {},
   "source": [
    "## Mocking Return Value\n",
    "\n",
    "You don't have to do a lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a6d2b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_mocking_return.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_mocking_return.py\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "\n",
    "from os import path\n",
    "    \n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_dirname(self):\n",
    "        with patch('os.path.dirname') as mock_dirname:\n",
    "            mock_dirname.return_value = 'hi there'\n",
    "            self.assertEqual(path.dirname('anything'), 'hi there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7657b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_mocking_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489d53f",
   "metadata": {},
   "source": [
    "## Fake\n",
    "\n",
    "In this example, our class uses an expensive API that we do not want to actually use in our test. We can fake the API so that our class thinks it's using the real thing, and then test that our class did the right thing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3e8b55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testsfolder/my_tests_mocking_fake.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testsfolder/my_tests_mocking_fake.py\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Assume this is in some API somewhere.\n",
    "class SomeExpensiveApi:\n",
    "    def __init__(self):\n",
    "        self.x = 10\n",
    "    def f(self):\n",
    "        return self.x\n",
    "    \n",
    "def get_expensive_thing():\n",
    "    return SomeExpensiveApi()\n",
    "\n",
    "# Assume this is our own class we want to test.\n",
    "class MyClass:\n",
    "    def g(self):\n",
    "        expensive = get_expensive_thing()\n",
    "        return expensive.f()\n",
    "    \n",
    "class MyTests(unittest.TestCase):\n",
    "    class MyFake:\n",
    "        def __init__(self, val):\n",
    "            self.val = val\n",
    "        def f(self):\n",
    "            return self.val\n",
    "        \n",
    "    def test_g(self):\n",
    "        with patch(__name__ + '.get_expensive_thing', new = lambda: MyTests.MyFake(20)):\n",
    "            m = MyClass()\n",
    "            self.assertEqual(m.g(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6b5af3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/davidpet/miniconda3/envs/ai/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest testsfolder.my_tests_mocking_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee405ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
