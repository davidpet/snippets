[Documentation]
docs.python.org

[Variables]
int, float, str, bool
True and False for bool
'' and "" equivalent
2 + 3j = complex
float is 64-bit minus some overhead
int is probably usually 64-bit (maybe minus some overhead) at first
    but dynamically sized for very large values so it can grow
    also some pooling/interning goes on

None = absence of value
    type is NoneType

type(x) for reflection
    type(x).__name__
dir(x) = get all the members of x
help(x) = get the docstring of x
isinstance(a, b)
NOTE: unlike in some languages, you don't need special operators to pass classes around
    eg. pass int to a function if need the int class for reflection purposes (as defaultdict takes in c'tor)

x = 3
    variable declarations are not typed
x = 'hi'
    can be set to a totally different type later

2., 2e9, etc. for floats
    float('inf') and float('-inf') to get infinities
        these act like you'd expect (eg. infinity always stays infinity when add finite numbers)
    float('nan')
        stays nan no matter what operations you do to it
    math.isnan(x)
    all comparisons (==, <, etc.) with nan automatically False, even if both sides are nan!

0b, 0x, etc. prefixes for binary, hex, etc.

Variable Scope (unusual)
    if you read a variable, it automatically looks from the current scope up to global as usual
    but when you write a variable, it will only go up to the function's scope and then create a new variable if not there
    this also means that variables don't nest within blocks in functions in the normal way
        with statements, while statements, if statements, etc. can declare and set a value within them and it works fine
    to make a truly local variable within a block, you'd have to enclose it in another function scope
        eg. a helper function, or a nested/lambda function
    you can use the 'global' keyword to write to a global variable instead of making a new local variable
        global x
        x = 100
    similarly, you can use 'nonlocal' (which cannot be used for globals) to assign to a higher nested function variable
        nonlocal x  # x is from function containing this function
        x = 100
    an advantage of this is to be able to create and set variables with multiple possible values in branches more concisely

there is no such thing as 'const' or 'final' to prevent modification
mutability and references
    l = [1, 2, 3]
    m = [l, l]
    l.append(4)
    print(m)   # [[1, 2, 3, 4], [1, 2, 3, 4]]

    def f(s):
        s.append(5)  # original affected
there is no such thing as a local static variable in Python
    some people create them like this:
        def f():
            if not hasattr(f, 'x'):
                f.x = 10
            else:
                f.x += 1
            return f.x
    other ways:
        default mutable args
        closures
        globals
        statics on a class

use \ at end of line to continue on next line
    may give you better result than how the formatter does long fluent API chains
also, wrapping in something like (), [], or {} causes a line continuation syntactically

python is very picky about indentation having to match and stuff like that

declaration order doesn't matter in the same way as other languages
    eg. within body of a function, you can use a variable that doesn't exist
    as long as it exists by the time the function is called elsewhere, it will work out
    this is the behavior of a scripting/interpretted language

you can check for the existence of a variable itself with:
    if 'x' in locals():  # note that we use string name of variable
      print(x)
    if 'x' in globals():
      print(x)

you can store variables on classes and functions that aren't defined in those places!
    this is what allows decorators to work
    it only works for stuff you define, not built-in stuff like integers and dictionaries
    eg. class MyClass:
          pass
        m = MyClass()  # note that you DO NOT USE NEW KEYWORD
        m.x = 10
        print(m.x)

    eg. def f():
          pass
        f.x = 10
        print(f.x)

    eg. def f():
            f.x = 5 # from within class, just use the name

Enums
    use the enum module (import Enum, auto, etc.)
    create an enum by either inheriting from Enum or creating an instance of Enum()
    in class version, each member is assignment
        either a value, or auto() call
    in functional version: Enum('Color2', ['RED', 'GREEN', 'BLUE'])

    ways to access:
        Color.RED
        Color(1)
        Color['RED'] # case sensitive
        for color in Color:
          print(color)
    
    each member is unique and singleton (with respect to both == and 'is')
        no matter how you access it above
    each member has a .name and .value (for the ordinal)

    enum class can have methods that can be called on the values (instances)

Default Values
    int() is 0
    float() is 0.0
    str() is ''
    bool() is False

[Collections]
collections in Python have literals but you can also use their explicit constructors (eg. list())
a lot of the stuff mentioned in list will apply other places

list
    x = [1, 2, 'hi']
    x[0] = 100 # mutable
    print(x[0])

    x.append(val)
    x.extend(y)
        destructively add elements of y to x (leaving y alone)
    x.insert(index, val)
    x.remove(val)  # first occurence
    x.pop()  # return and remove last item
    x.pop(index)  # return and remove item at index
    del x[index]
    del x[low:high]
    x.clear()
    x.reverse()
    x.copy() [shallow copy]
        x[:] is same thing
    x.index(item) for finding index of item in list from left side
        raises ValueError if not found
        linear search

    sum(l), max(l), min(l) top-level functions
        these also have variadic parameter versions
            eg. max(a, b, c)

    l.sort() destructive, sorted(l) non-destructive (copy)
    l.reverse() desturctive, reversed(l) non-destructive (copy)

    x = a + b + [1, 2] # concatenation (non-destructive)
        use a.extend() for destructive

    x == y # value equality implemented
    x = [0] * 100 # initialize with 100 0s

tuple
    x = (1, 2, 'hi')
    x = 1, 2, 'hi'
    # immutable!
    print(x[0])

    y = (1,)    # single value tuple syntax

    () = empty tuple

    and some of the stuff from list above

set
    x = {1, 2, 3} # mutable
    x.add(4)
    x.update([5, 6, 7]) # any iterable
    x.remove(7)  # raises error if not present
    x.discard(6)  # does not raise error if not present
    x.pop()   # remove and return arbitrary item
    x.clear()

    bitwise and minus operators overloaded to do set operations
    also set.intersection(s1, s2) static method
    also s1.intersection(s2) mutation

    NOTE: you cannot use {} as empty set because it's ambiguous with empty dict
        have to use set() constructor

dict
    x = {'a': 1, 'b': 2} # mutable
    x['c'] = 3
    # NOT ALLOWED: x.c = 3
    print(x['c'])  # raises KeyError if not present
    print(x.get('c', 0))   # default value if not present
    del x['c']
    x.pop('b')
    x.clear()

    default iteration and membership checks are for keys
    you can be more explicit: x.keys(), x.values(), x.items() which are tuples of key and value
        these are sequences, not lists or tuples (doesn't usually matter)

    empty dict = {} or dict()

collections.deque
    double-ended queue
    can serve as an efficient stack, queue, or linked list
        because it's backed by a linked list
    like Java's LinkedList, since you're behind an interface that forces O(n) indexing
        it's not as efficient as implementing your own for certain operations
    otherwise, it more or less looks like a list with some extra members
        where certain operations under the hood have different performance characteristics
    
    append() goes to right side in O(1)
    appendLeft() goes to left side in O(1)
    pop() comes off the right side in O(1)
    popLeft() comes off the left side in O(1)

    you can construct with a maxlen optionally
        means if you add on one side and it goes above that len, items will fall off the other side
Stack
    use list with append() and pop()
    can peek with l[-1]
    or use collections.deque
    list one is probably ok since not recopying whole array, just growing and shrinking
Queue
    use collections.deque because inserting at beginning is super costly
    similar to list but popleft() and popright()
    still use append()

bytes
    x = b'abc=xff' # char and hex values

Cloning
    x = [*y] makes a shallow copy of list y into x
    x = [**d] makes a shallow copy of dictionary d into x
    x = list(y) is another way to clone (like a copy constructor)
        often take an iterable rather than specific type
        so that you can also do conversions
Conversions
    x = set(l) # list to set (to dedupe)
    x = list(set(l)) # list to list with deduping
Unpacking
    x, y, z = collection
        works for tuple, list, or other sequence
        as long as the length of the collection matches the # of variables
    [x, y, z] = collection
        means the same thing as above (regardless of whether list or tuple)    
Iteration
    for item in l:
        print(item)

    if an object is iterable, it will have an __iter__() method to return an iterator
    a generator function works as an iterator (supports the iterator interface)
    you can also make a class that has a __next__(self) method and return that
        python will call __next__() on the iterator as needed to get the next item
        it should raise StopIteration when there are no more items
    
    iterators can be directly used like this:
        it = iter(collection)
        while True:
            try:
                print(next(iter))
            except StopIteration:
                break
        
Membership
    if item in l:
        print('yes')

    all(item in small_list for item in l)
        a way to check if all items are in a collection
Comprehensions
    in general, look like the literal for the collection you're making
        with a for loop inside to generate the elements
    
    squared = [x**2 for x in nums]
    name_lengths = {name: len(name) for name in names}
    unique_vals = {x for x in nums}

    a special exception is with tuples and Generators
        gen = (x**2 for x in nums)
            this is a GENERATOR COMPREHENSION instead of TUPLE
        tup = tuple(x**2 for x in nums)
            this is a TUPLE COMPREHNSION (technically casting generator)

    nesting is done with 2 for loops inline
        [x**2 for row in matrix for x in row]
            this flattens the matrix and gets the squares of its elements as a flat list

    conditional comprehension with 'if'
        even_squares = [x**2 for x in nums if x % 2 == 0]

    generator comprehensions can also be used directly as function call params
        f(x**2 for x in range(10))
            f() will get called with 1 arg, the generator (which is iterable)

Negative indices
    -1 = last item, -2 = 2nd to last item, etc.
Slicing
    [2:5] # includes 2, 3, 4
    [:2] # includes 0, 1
    s[-2:] # includes last 2 items only
    s[:-1] # excludes last item
    s[start:stop:step] # full version (all 3 can be left off and/or negative)
        step -1 can be used to REVERSE the order
        but the start and stop are taken literally and might end up empty
        (ommiting start or stop is a special case where it will smartly adapt)
    you will get empty list for invalid range (not throw)

    for mutable collections, slices can be assigned
        eg. assign [] to clear that range
        eg. del operator on the slice to clear that range
        eg. assign a list to change that range (even on size mismatch)
    however, when stored as a variable, slices are COPIES of parts of the list
Ranges
    the range() function works similar to slicing
    it returns an iterable that you can use with a 'for' loop
Sorting
    sorted(l, key = fn, reverse = False)
        fn should return value to sort by (can be derived/transformed arbitrarily)
        ascending by default, can also reverse it for descending
        the sort key will be used for sorting using the < operator
            if the sort key is a custom class (or no sort key so elements used), then __lt__ will be called
    the rough java equivalent is:
        < operator = Comparable<T> implementation
        key = Comparator passed in to override that
Searching
    bisect module has bisect_left and bisect_right to do binary search on sorted collection
    bisect_left(sorted, item) uses < operator to look for leftmost occurence (and get index)
    bisect_right(sorted, item) uses < operator to look for 1st item after rightmost occurence
        can use as exclusive upper bound if want to take whole range
    both let you pass in low and high bounds of the search as well as a key
    if the index returned is len(sorted), then the insertion point is at the end (and item is not found)
        or in the case of bisect_right, the item you wanted might be the last thing in the array (special case)
    otherwise, you can tell if it was found or not by doing == on sorted[index]
Objects as keys
    any of the built-in collections are hashable and thus can be used as keys
    your own classes can be hashable if you implement the right stuff too
Implementing Objects for Collections
    == operator is used for membership tests
    < operator is used for sorting and binary searching
    hash() is used for dict insertion
    hash() and == are used for dict retrieval
    repr() is used for printing collections (trickles down to elements)
    str() is used for converting collections to string (trickles down to elements)

Not Available:
    persistent slice that responds to changes in original and/or can be used to modify the original

[Strings]
# for comments

'' and "" are same (and allow to use other unescaped)
''' and """ are multi-line strings
r'' and r"" are raw strings
f'' and f"" and f''' and f""" are f-strings

immutable (modifications return copy)
    you can get a mutable copy as a list of chars with list(s)
        make back into string with ''.join(c)

strip() to remove leading/trailing whitespace
replace(old, new)
upper(), lower()
split(delim) -> gets list of strings (similar logic to Java but not regex)
delim.join(l) -> join a list by a delim string (method of str)

s = s1 + " " + s2

if substring in s:   # substring search
    print('present')
s.index(substring)   # explicit search
s.count(substring)

formatted strings
    NOTE: with any of these, you can store the template as a variable in itself
        though in an f-string, that would already be evaluated
    
    f'Hi, my name is {name} and I am {age} years old.'
        name and age should be variables in the encosing scope
    'Hi, my name is %s and I am %d years old' % (name, age)
        this is the old-fashioned way, replaced by f-strings above
        for single value, no () needed
    'Hi, my name is {} and I am {} years old.'.format(name, age)
    'Hi, my name is {name} and I am {age} years old.'.format(name=name, age=age)

    {:.2f} (example of format specifier - in this case float with 2 places after decimal point)

string as collection
    len(s)
    s[0], s[-1], s[1:3]
        none of these support assignment
        slicing gives another string
    for c in s:
        print(c)
    l = list(s)   # mutable copy as list of characters

    NOTE: character is not a type - it is just a string of length 1

regular expressions
    see 're' in 'stdlib' section

'string' package
    for getting list of ascii letters, punctuation, etc.

[Operators]
mostly the same as C-like languages with some exceptions
    additional operators like // and ** also support assignment (//= and **=) like others

missing
    ++ and --
division
    // behaves like / in c-like languages (floor division)
    / becomes a float instead!
exponentiation
    a**b means a to the b power
boolean
    use words and, or, not instead of operators &&, ||, !
    eg. a and not b
bitwise
    unlike booleans, these use the usual symbols (&, ^, ~, >>, etc.)

presence in collection (boolean)
    a in somelist
    b not in somelist

equality
    a is b
        True if same numeric value or same reference
        same as == in Java
    a is not b
        opposite of a is b
    a == b
        value equality
        more like .equals() in Java
    a is None
        considered better than doing a == None

truthiness
    since types aren't bound, there is a lot of flexibility for checks on variables
    the following values are falsey in conditionals:
        None
        False
        not True
        0
        ''
        []
    the rest are truthy
    you can disambiguate None from [], for instance, using is None first
    operators like and, or, not make into true booleans first

ternary
    no ? : like in C-like languages
    instead it looks like:
        a if a > b else b

collections
    [1, 2] * 3
        [1, 2, 1, 2, 1, 2]
    [1, 2] + [3, 4]
        [1, 2, 3, 4]
    [*mylist]
        spread operator (in this case copying mylist)

del
    x = 5
    del x
    print(x)    # Error
    del x,y   # delete multiple

    l = [1, 2, 3]
    del l[1]  # l = [1, 3]
    l = [1, 2, 3]
    del l[1:] # l = [1]

    del mydict[key]

hasattr(obj, name) to see if an attribute exists on an object
    useful if you're going to be hiding variables in functions, for instance
    eg. hasattr(x, 'count')

[Control Flow]
; isn't required, but it is a way to fit multiple statements on one line
    eg. for shell one-liners

pass
    a noop statement
    eg. for an empty loop or function body (because required to have something there)

if a < b:
    print(a)
elif b < a:
    print(b)
else:
    print('same')

while a < b:
    a += 1
    print(a)

for element in l:
    print(element)

for index, element in enumerate(l):
    print(index, element)

for x, y in l:
    # each element of l is a tuple which is unwrapped here

for i in range(10):
    print(i) # 0, 1, 2...9

break and continue supported as usual

match term: # like switch in another language
    case 'bla1':
        print('bla1')  # no fall-through, so no break needed
    case 'bla2':
        print('bla2')
    case _:    # like default in another language
        print('default')

try:
    someCodeThatMightThrow()
    raise MyThrownException('I threw')
    print('this code is unreachable')
except ZeroDivisionError:
    print("division by zero!")
except MyThrownException as e:
    print("Error: " + str(e))
except (OtherError1, OtherError2) as e:
    print("Either OtherError1 or OtherError2" + str(e))
finally:
    print("this will run no matter what")

some built-in errors:
    KeyError
    AttributeError
    StopIteration

with open('myfile.txt') as f: # context management
    contents = f.read()
print(contents) # notice contents variable still lives (as does f, but in a closed state)

with open('myfile.txt'):
    print('not necessary to keep variable - context is still active')
with open('myfile.txt') as f, open('myfile2.txt') as g:
    print('2 contexts at same time!')

[Functions]
def f(a, b, c):
    return a + b + c
x = f(10, 20, 30)

Overloading
    true overloading does not exist
    if you define the same name twice, the later one replaces the earlier one, even if params are different
    you have to simulate overloading with default args and keyword args
Tuples
    return (a, b)
        use tuple to return multiple values from a function
    a, b = f(x)
        tuple unwrapping in-place
Default args
    def f(x, a=0, b=0):
        pass
    f(10)
    f(10, 20)
    f(10, 20, 30)

    def f(a=g()):  # not a "compile-time constant"
        return a
Default Mutable args
    this is a weirdness of Python
    when a default value of an arg is a mutable type like a list or dictionary
        then modifying it within the function will modify the default (because it's cached that way)
    eg. def f(x, a=[]):
            a.append(x)
        # every call to f without an a arg will grow the default a arg
        # if you call with an a value, then call again without one, the cached one will come back
Keyword args
    using same f as "Default args" above
    f(10, b=1000, a=700)
    f(10, b=10)

    f(a=a)
        something you commonly see when delegating args
        Python knows the difference between the left and right side of this
Default return
    when a function doesn't have a return statement, or reaches the end without returning
    it returns None (which you can ignore to make it simulate void in other languages)

Spread (star and double-star)
    f(10, arg=100, *l, **k)
        l = positional args expanded in-place
        k = keyword args expanded in-place
        a way to forward variadic args
            in addition to using collections to store args
Rest/Variadic (star and double-star)
    def f(x, a=10, *args, **kwargs):
        pass
    args becomes a list of positional args passed in besides the named ones
    kwargs becomes a dictionary of keyword args passed in besides the named ones

Generators (lazy)
    def f():
        yield 1
        yield 2
    print(list(f())) # evaluate whole thing

    def g(seq):  # lazy sequence in terms of another lazy sequence
        for item in seq:
            yield item**2
    print(list(g(f())))

    def h():
        yield 0
        yield from f()  # expanded in-place (like * operator)
        yield 3

    def i():
        x1 = yield 0
        x2 = yield x1 * 10
        yield x2 * 20

    # two-way communication
    gen = i()
    next(gen) # 0
    gen.send(100)
    next(gen) # 1000
    gen.send(1000)  # x2 becomes None if you don't call this
    next(gen) # 10000
    next(gen) # raises StopIteration
    # you could use the gen.send() values to actually detect when to stop returning (eg. break a loop)

[Functional]
f = lambda: print('hi')
g = lambda x: x**2
h = lambda x, y=10, *args: x + y + max(args)
def myfunc(x):
    print(x)
x = myfunc

f()
print(g(10))
print(h(10, 20, 30, 40))
x(10)

nested functions are allowed and can be used like lambdas too
    def f():
        def lam():
            print('hi')
        return lam
    f()()

    NOTE: this is the only way to do multi-statement lambdas in Python
        there is no way to have {} around a body like in other languages

ignored params: _, __, etc.
    you can use these in a function or a lambda as params
    they are technically real names and can be used as such
        but by convention, they are ignored params
        usually to make args match without losing readability
    eg. for _ in range(10):
            print('hi')   # print 10 times, don't need index
    eg. a, _ = f()  # unwrap without length error, but only need 1st thing

functional operations
    map
        seq = map(lam, l) # lazy sequence
        print(list(seq))

        NOTE: you can often do LIST COMPREHENSIONS instead
    reduce
        val = functools.reduce(lam, l, seed)
        print(val)
    filter
        seq = filter(lam, l)
        print(list(seq))

        NOTE: you can often do LIST COMPREHENSION with an 'if' inside

    zip
        multiple lists to list of tuples
            seq = zip(l1, l2, l3)  # variadic
            for i1, i2, i3 in seq:
                print(i1, i2, i3)
        list of tuples to multiple lists
            l1, l2, l3 = tuple(zip(*seq))
        parallel iteration
            for i, j in zip(is, js):
                print(i, j)

        NOTE: zip is lazy like the other functional operations
        
    all
        all(seq) = True if no elements are falsey (inc. if empty)
    any
        any(seq) = True if at least one element is truthy (false if empty)

itertools
    see stdlib section below
    itertools lets you do various stream operations for declarative lazy sequence processing

Closures
    python closes BY REFERENCE over variables by default
        for i in range(10):
          yield lambda: print(i)
        This will print 9 over and over (10 times)
            because i is captured by reference even though it's primitive!
            then the lambdas are returned all closing on the same variable that continues to live
        This happens with nested functions too, not just lambdas!
    in order to close BY VALUE instead, you need a lexical capture point (a function call)
        def make_lambda(x):
          return lambda: print(x)
        for i in range(10):
          yield make_lambda(i)
    the good part about this behavior is you can modify the state
        eg. increment a counter, iterate lines in a file, etc.
    just remember that when it's a parameter, it's by value and when it's implicitly captured, it's by reference

Class Method References
    m = MyClass()
    map(m.f, l)
        method f of class MyClass is BOUND to instance m
        map() will call it like a pure function, and m will automatically be passed as self
        NOTE: if you see lambda x: m.f(x), you can probably just replace that with m.f
    MyClass.f(m)
        method f of class MyClass is UNBOUND, so you have to pass an instance as the first arg

[Classes]
'self'
    similar to how you have to put 'this' everywhere in JS, you need 'self' to access instance members
    in addition, you have to explicitly pass 'self' as the first param of instance methods!
Inheritance
    uses a prototype-like inheritance (similar to JS)(but no prototype member)
    static data lives on the class and then gets copied to instances (like a stamp)
    the instances are then independent from that point on

    no 'virtual' keyword - everything is virtual (like Java) due to how the lookups work
        just using the same name overrides already

    diamond inheritance
        ambiguity resolved by taking first thing from left in class's inheritance list (MRO)

    unlike other languages, base c'tor is only automatically called if derived class has no c'tor!
        can explicitly call it like below though
object
    the root of the type system is called 'object'
    even primitives inherit from object
    the default hash function returns a different hash for each instance
        which makes it useful for unique opaque dictionary keys and such
    object can be directly instantiated too
        eg. to use as opaque key or something
Access Modifiers
    apply within classes as well as top-level things in modules
    default = public
    _ = protected
        only by convention (not enforced)
    __ = private
        enforced by NAME MANGLING at runtime
            though the mangling is predictable and defeatable
    __somename__ = not an access modifier but a special value with special meaning

class MyClass:
    static_var = 10
    other_var = static_var  # no self needed because not in a method

    def __init__(self, instance_param):
        self.instance_var = instance_param

    def f(self, x):
        print(x)
        print(self.instance_var)

class MyDerivedClass(MyClass):
    def __init__(self, instance_param):
        super().__init__(instance_param)
        self.derived_var = 10

    def f(self, x):
        print('inherited!')
        print(x)

    @staticmethod   # special attribute for static method
    def g(x):       # no self needed for static
        print(x)

    @classmethod
    def h(cls):     # class passed as arg
        print(cls.static_var)

class MultipleDerivedClass(BaseClass1, BaseClass2):   # no restriction
    pass

m = MyClass(x)  # self passed implicitly
print(m.static_var)  # this is actually a copy now
print(MyClass.static_var)
print(m.instance_var)
m.f(100)

MyDerivedClass.g(100)
MyDerviedClass.h()

Interfaces
    python doesn't have interfaces - everything is duck-typed
    as long as the things referenced or called by the caller are on the object, it works

Special Class Members
    certain members can be present on your class to implement certain behaviors in python

    __init__(self, ...) = c'tor
    __del__(self) = d'tor

    __str__(self) = converting object to string
        eg. str(m)
    __repr__(self) = string representation for debugging
        eg. print(m)

    __len__(self) = length of the collection
    __iter__(self) = iterator class or generator function for iterating elements
    __contains__(self, item) = membership check

    __getitem__(self, index) = index operator (index could be anything you want)
    __setitem__(self, index, value) = setting value by index
    __delitem__(self, index) = deletion of value by index

    __getattr__(self, name) = for reading values from an instance with . operator (as if fields)
    __setattr__(self, name, value) = for dealing with assignment via .
    __delattr__(self, name) = for deleting with deleting attributes via .

    __getattribute(self, name)__ = generic attribution retrieval

    __call__(self, ...) = call operator - for calling object as if it is a function
    __enter__ and __exit__ for context management

    __eq__(self, other), __lt__(self, other), __add__(self, other), __sub__(self, other), __and__(self, other), etc.
        implementations for operators like ==, <, +, -, etc.
    __bool__(self), __int__(self), etc. for type conversions
    __hash__(self) = for hasing (eg. in dict)

    NOTE: a lot of these methods have top-level functions without underscores you can call to invoke them conveniently
        eg. instead of m.__hash__(), you can call hash(m)
        eg. hash(), str(), len(), iter(), etc.

Properties
    class Circle:
        def __init__(self, radius):
            self.radius = radius

        @property
        def diameter(self):
            return 2 * self.radius

        @diameter.setter
        def diameter(self, value):
            self.radius = value / 2

        @property
        def area(self):
            return 3.14159 * self.radius**2

    circle = Circle(1)
    print(circle.diameter)
    circle.diameter = 4
    print(circle.diameter)
    print(circle.area)

Dataclass
    (for simple POD types)

    from dataclasses import dataclass

    @dataclass
    class MyClass:
        x: int  # required constructor arg
        y = 20  # optional constructor arg

        def f(self):
            return self.x + self.y

        # __init__ defined for you
        # has the member fields in order
        # ones with values are optional

    m = MyClass(10)
    print(m.f())

[Generics]
because python is dynamically weakly typed and duck-typed, it does not have generics
any collection is a generic, with no constraints at all on elements (can mix and match however)
however, you can somewhat simulate it at least in type hints using Typing.TypeVar (for type checking purposes only)

[Imports/Exports/Modules]
import os
import sys
print(os.path)

import os, sys
print(os.path)

import os as operating_system, sys as system
print(operation_system.path)

from os import path
# avoid having to always use fully-qualified path
# works for module as well as symbols within module
print(path)

from os import path as os_path
# this works for renaming modules as well as symbols inside modules
print(os_path)

from os import *
# import all symbols (usually not recommended)

anything can be at the top-level of a module (variables, classes, functions, etc.)

python3 myfolder/myfile.py
    direct execution
    search path not used
python3 -m myfolder.myfile
    module execution
    search path used
        each . is a subfolder, but the root can be anywhere in search path
        this allows you to execute libraries and installed dependencies this way too
        current working directory, PYTHONPATH variable, installed packages, etc.
python3 -c 'import myfolder.myfile'
    execution via import (within one-liner shell command)
python3 -c 'from myfolder import myfile; print(myfile)'
    multiple statements within 1 line

__name__
    '__main__' for direct execution or module execution
    name of the module itself if executed via an 'import' instead
        either via -c or via executing another  .py file

    very common to see if __name__ == '__main__' at top-level to distinguish library vs. script execution
        eg. could run unit tests for script version

__file__
    path of the .py file (the current one, not the top level one)

sys.argv[0]
    the top-level thing being executed (instead of current file)
    for direct and module, it is the current file, but for imports, it's the thing executing at the top
    for one-liners that import the file, it's just -C
sys.argv[1:]
    args to the top-level script (passed to python3)
    things like --flag are passed exactly like that as 1 arg
    things like -n 5 are passed as 2 args exactly like that one after the other
argparse built-in library can help parse the arguments
common pattern in pip packages to have a dictionary of command name to function to call
    then use 1st arg as command and forward args to the function with * operator

package
    if a folder has an __init__.py file, it is a package
    a package will import subpackages (usually relative with . and ..)
        eg. from .deepsubfolder import deepmodule
            then it's available as mypackage.deepmodule to the caller
    packages can be in a hierarchy of other packages
    importing from subfolders directly won't work - you have to import the package and let __init__.py set it up

name clash issue
    if you name a file the same as an api you're calling, it will try to import itself
    the symptom of this will be that the import is empty
    another place this comes up is if a folder is named after a script (causing ambiguity)

[stdlib]
print(x)
print(x, y, z)
    print 3 values with space in between on single line
print() for newline only
print(x, y, z, sep='\t', end='')
    overriding sep and end
    in this case, tab between x, y, and z, and no newline at end
print("x:", x)
escape sequences for color (have to escape back again)
    alternatively, use a library like termcolor

open() for file I/o doesn't need an import
    with open(path, 'r') as file:  # open for text read
        for line in file:          # iterate lines (inc. newlines)
            print(line.strip())    # strip whitespace
        
        lines = file.readlines()   # list of lines (inc. newlines)

        content = file.read()      # read whole file as single string
other open modes include:
    w = write (use write() method which does not write a newline) (use \n)
    a = append
    b = binary (bytes instead of str)
    eg. 'wa', 'wb', 'rb', etc.

math
    isnan(x)
    isclose(x, y)
        for float near-equality
    sqrt(x)
    floor(x)
    exp(x) [e to the x]
    log(x) [natural log]
    log(x, base)
    radians(angle)
    cos(radians)
    pi = constant
    e = constant
statistics
    mean(l)
random
    seed(value)
    randint(inclusiveLower, exclusiveUpper)
    random() [float from 0 to 1, not including 1]
    shuffle(l) [destructive]
bisect
    bisect_left(sorted, element)
    bisect_right(sorted, element)

functools
    reduce() [but map and filter are in global/default namespace]

itertools
    chain(seq1, seq2)
        concatenates multiple sequences lazily into one sequence
    cycle(seq)
        lazily repeats a sequence forever
    repeat(val, n)
        lazily repeats a value n times
    combinations(seq, length)
        all combinations of 'length' elements of seq 
            only unique combinations, with same element not being paired with itself
    permutations(seq)
        all possible permutations of sequence

collections
    defaultdict: dictionary with default values for keys not present
        d = defaultdict(int)  # specify the type in c'tor
        print(d['notpresent']) # 0
        d['notpresent'] += 1 # becomes 1
        trying to get or set the key makes it present from then on
    Counter: count dictionary
        counts = Counter([1, 1, 2, 3, 3, 3, 4])
        print(counts[1])  # 2 because there are 2 1s
        print(counts[0])  # 0 because not present
        print(counts.most_common(2)) # [(3, 3), (1, 2)]
        print(counts.most_common(1)[0][0]) # 3
        print(sum(counts.values()))  # total count
    namedtuple: tuple with named fields (like a struct)
        acts like a normal tuple and a class at same time
    deque: double-ended queue
        more efficient than regular lists for stack and queue operations

    abc (abstract base classes)
        Callable = type annotation for a fn
        Sequence = type annotation for a generic sequence

os
    path
        expanduser('~/subfolder') -> '/home/username/subfolder' for instance
        abspath(path)
        relpath(abspath, relativeToPath)
        dirname(path) -> parent folder of file or folder
        basename(path) -> remove extension if present
        splitext(path) -> split into basename and extension parts
        join()
        exists()
        isfile()
        isdir()
    walk(path)
        pre-order DFS (alphabetical) of folder tree starting at root
        iterable of tuples of 3 items so you can do this
            for dirpath, subdirnames, filenames in os.walk('.'):
              print(dirpath, subdirnames, filenames)
        paths are made to look like what you passed in (relative of absolute)
        what you see in subdirnames, you are about to go into on a future iteration
            but the current iteration is your chance to deal with the files themselves
    listdir()
        list files and folder (by name) in current working directory (or given directory)
    getcwd()
    chdir()
    mkdir()
    makedirs() [to make multiple levels]
    rmdir() [must be empty]
    environ = dictionary of environment variables (no $)
        can be used to get/set in current shell instance
    getenv(varname, default)
    putenv(varname, value)

shutil = higher-level OS file system functionality than os
    copy()
    move()
    rmtree() [doesn't require empty]
    make_archive() [to make zip file]
    unpack_archive() [to unzip]

sys
    argv = list of cmdline args (element 0 = the top-level call such as the python file)
    exit(code) = exit whole program with exit code
    stdin, stdout, stderr
    path = module search path (list of strings)
        can append to it to add to the search path dynamically before importing a module
    platform = OS info
    version = Python version
    modules = currently imported modules

glob
    glob('**/*.py')
        recursive list of all python files in all subfolders in current working directory

re
    sub(regex, replacement, text) -> returns new text
    findall(regex, text) -> list of all substrings matching

string
    ascii_letters = collection of all ascii letters
    punctuation = collection of all punctuation chars

pickle: read and write objects as binary file content
    dump(obj, file)
    load(file)

    file must be open with open() as usual
    depends on __getstate__ and __setstate__ members of object
        the built-in stuff has it already

copy
    deepcopy(obj)
        depends on __copy__ and __deepcopy__ existing on object (as built-ins have)

time
    deals with seconds (as floats)
    time()
    sleep(time)

asyncio
    lets you do async/await type stuff just by importing it (without having to reference)

    async def f():
        return 10

    async def g():
        x = await f()
        return x

    val = asyncio.run(g)  # top-level, once per program, to kick off the async graph
    print(val)

    see also: async with, asyncio.gather(), asyncio.Lock (async/await friendly alternative to threading.Lock)

argparse
    parser = argparse.ArgumentParser()
    parser.add_argument(...) to add each arg and info about it one by one
    args = parser.parse_args()
    args.field1, args.flag, etc. then available

dataclasses
    dataclass: decorator for defining a data class

logging
    basicConfig()
    logger = getLogger()
    logger.info('this is an info message')
    logger.error('this is an error!')

importlib
    reload(module): to reload a module (eg. to test changes)
        reloads all references to same module even if imported multiple times in different ways
    
typing
    Any
    TypeVar
    Union
    Optional

enum
    Enum
    auto

[pip]
** for any interactive command, use -y or -n switch to make it non-interactive**

pip install termcolor
    install package and make importable
pip install --upgrade termcolor
    install or update package
pip install termcolor==2.3.0
    install specific version
    downgrades if necessary
pip install 'termcolor>=1.1,<1.2'
    install from a range of versions

pip show termcolor
    print info about installed package
pip uninstall termcolor
    uninstall a package

pip list
    show installed packages
pip list --outdated
    show list of outdated packages

wheel = pre-built binary package for python
    can be installed via pip
    see Modules notebook for more details about wheels when needed (esp. the Apple and TensorFlow stuff)

[conda]
conda update conda
conda env list
conda create -y -n conda-demo python=3.11
conda activate conda-demo
conda deactivate
conda install termcolor
conda env export >env.yaml
conda env remove -y -n conda-demo

conda manages:
    python version
    pip packages
conda does not manage:
    working directory
    apt packages
    node packages
conda manages things by messing with PATH as you activate and deactivate environments

[3rd party libraries]
termcolor
    from termcolor import colored
    print(colored('hi', 'red', attrs=['bold']) + ' there')
    colored() just makes text with escapes inside which can be concatted with un-colored text

[decorators]
function or callable class that wraps a function or class
    either returns it with some change, or returns another one wrapping it
eg. add attribute to function
eg. wrap a function in another function that does logging

def mydecorator(fn):
    def wrapper(*args, **kwargs):
        print('called')
        return fn(*args, **kwargs)
    return wrapper

@mydecorator
def myfn(x):
    return x**2

myfn(10)
    returns 100 and also prints 'called' because of the decorator
    myfn gets replaced by the decorator version right away

built-in decorators:
    @property: lets you treat a method as an attribute
    @staticmethod
    @classmethod
    @abstractmethod

[docstring]
""" multi-line strings in certain places
top of module for module documentation
top of function (below prototype - indented) for function docstring
top of class (below name - indented) for class docstring
after variable (eg. a constant)
can be one-line (all in one line) or have a space between the headline and the longer description

[type hints]
type hints aren't part of the actual execution of the program
    just for type checkers if you have one setup
    they can be arbitrarily left out, applied inconsistently, even wrong (if the type checker isn't aggressive or not set up)
the syntax is very similar to TypeScript

def add_numbers(a: int, b: int) -> int:
    return a + b

def print_this(a: int) -> None:
    print(a)

def do_stuff(a: int = 10, b: int = 5) -> int:
    return a + b

def add_numbers_list(l: list[int]) -> int:
    return sum(l)

def add_numbers_dictionary(d: dict[str, int]) -> int:
    return sum(d.values())

# This will still technically work if you pass <3 or >3 args.
def add_numbers_tuple(t: tuple[int, int, int]) -> int:
    return sum(t)

# aliases
Point = tuple[float, float, float]
Points = list[Point]

def centroid(p: Points) -> Point:
    return tuple(mean(axis) for axis in tuple(zip(*p)))

# variables
x: int = 5
y: Any = f() # any type (must be imported from Typing)

# collections.abc imports
# Callable (for functions)
def transform(list1: list[int], list2: list[int],
              fn: Callable[[int, int], int]) -> list[int]:
    return [fn(left, right) for left, right in zip(list1, list2)]
# Sequence (for sequences where you don't know if list, tuple, etc.)
def add_numbers(s: Sequence[int]) -> int:
    return sum(s)

# Generics (simulated)
from typing import TypeVar

T = TypeVar('T')

def first_thing(s: Sequence[T]) -> T:
    return s[0]

# Type union (shorthand for typing.Union[])
def make_str(a: int | str) -> str:
    if isinstance(a, int):
        return str(a)
    return a

# shorthand for typing.Optional[]
def coalesce(a: int | None) -> int:
    if a is None:
        return 0
    return a

[unit tests]
** see Unit Tests notebook **
not going to show much of it here
it works much like JUnit type stuff from other languages
class is instantiated to run test method
setup and teardown, etc.
mocking, faking, etc. available

[Jupyter]
throughout the notebooks, there are examples of jupyter usage
I did not include those here for now
