[Documentation]
docs.python.org

[Variables]
int, float, str, bool
    technically all reference types, but int, float, and bool are immutable
        thinking of them as primitive value types will pretty much always get you the right result though
True and False for bool
'' and "" equivalent
2 + 3j = complex
float is 64-bit minus some overhead
int is probably usually 64-bit (maybe minus some overhead) at first
    but dynamically sized for very large values so it can grow
    also some pooling/interning goes on

None = absence of value
    type is NoneType

type(x) for reflection
    type(x).__name__
dir(x) = get all the members of x
help(x) = get the docstring of x
isinstance(a, b)
NOTE: unlike in some languages, you don't need special operators to pass classes around
    eg. pass int to a function if need the int class for reflection purposes (as defaultdict takes in c'tor)

x = 3
    variable declarations are not typed
x = 'hi'
    can be set to a totally different type later

2., 2e9, etc. for floats
    float('inf') and float('-inf') to get infinities
        these act like you'd expect (eg. infinity always stays infinity when add finite numbers)
    float('nan')
        stays nan no matter what operations you do to it
    math.isnan(x)
    all comparisons (==, <, etc.) with nan automatically False, even if both sides are nan!

0b, 0x, etc. prefixes for binary, hex, etc.

Variable Scope (unusual)
    if you read a variable, it automatically looks from the current scope up to global as usual
    but when you write a variable, it will only go up to the function's scope and then create a new variable if not there
    this also means that variables don't nest within blocks in functions in the normal way
        with statements, while statements, if statements, etc. can declare and set a value within them and it works fine
    to make a truly local variable within a block, you'd have to enclose it in another function scope
        eg. a helper function, or a nested/lambda function
    you can use the 'global' keyword to write to a global variable instead of making a new local variable
        global x
        x = 100
    similarly, you can use 'nonlocal' (which cannot be used for globals) to assign to a higher nested function variable
        nonlocal x  # x is from function containing this function
        x = 100
    an advantage of this is to be able to create and set variables with multiple possible values in branches more concisely

there is no such thing as 'const' or 'final' to prevent modification
mutability and references
    l = [1, 2, 3]
    m = [l, l]
    l.append(4)
    print(m)   # [[1, 2, 3, 4], [1, 2, 3, 4]]

    def f(s):
        s.append(5)  # original affected
there is no such thing as a local static variable in Python
    some people create them like this:
        def f():
            if not hasattr(f, 'x'):
                f.x = 10
            else:
                f.x += 1
            return f.x
    other ways:
        default mutable args
        closures
        globals
        statics on a class

use \ at end of line to continue on next line
    may give you better result than how the formatter does long fluent API chains
also, wrapping in something like (), [], or {} causes a line continuation syntactically

python is very picky about indentation having to match and stuff like that

declaration order doesn't matter in the same way as other languages
    eg. within body of a function, you can use a variable that doesn't exist
    as long as it exists by the time the function is called elsewhere, it will work out
    this is the behavior of a scripting/interpretted language

you can check for the existence of a variable itself with:
    if 'x' in locals():  # note that we use string name of variable
      print(x)
    if 'x' in globals():
      print(x)

you can store variables on classes and functions that aren't defined in those places!
    this is what allows decorators to work
    it only works for stuff you define, not built-in stuff like integers and dictionaries
    eg. class MyClass:
          pass
        m = MyClass()  # note that you DO NOT USE NEW KEYWORD
        m.x = 10
        print(m.x)

    eg. def f():
          pass
        f.x = 10
        print(f.x)

    eg. def f():
            f.x = 5 # from within class, just use the name

Enums
    use the enum module (import Enum, auto, etc.)
    create an enum by either inheriting from Enum or creating an instance of Enum()
    in class version, each member is assignment
        either a value, or auto() call
    in functional version: Enum('Color2', ['RED', 'GREEN', 'BLUE'])

    ways to access:
        Color.RED
        Color(1)
        Color['RED'] # case sensitive
        for color in Color:
          print(color)
    
    each member is unique and singleton (with respect to both == and 'is')
        no matter how you access it above
    each member has a .name and .value (for the ordinal)

    enum class can have methods that can be called on the values (instances)

Default Values
    int() is 0
    float() is 0.0
    str() is ''
    bool() is False

[Collections]
collections in Python have literals but you can also use their explicit constructors (eg. list())
a lot of the stuff mentioned in list will apply other places

list
    x = [1, 2, 'hi']
    x[0] = 100 # mutable
    print(x[0])

    x.append(val)
    x.extend(y)
        destructively add elements of y to x (leaving y alone)
    x.insert(index, val)
    x.remove(val)  # first occurence
    x.pop()  # return and remove last item
    x.pop(index)  # return and remove item at index
    del x[index]
    del x[low:high]
    x.clear()
    x.reverse()
    x.copy() [shallow copy]
        x[:] is same thing
    x.index(item) for finding index of item in list from left side
        raises ValueError if not found
        linear search

    sum(l), max(l), min(l) top-level functions
        these also have variadic parameter versions
            eg. max(a, b, c)
        these can take `key` param to customize what you take the max and min by

    l.sort() destructive, sorted(l) non-destructive (copy)
    l.reverse() desturctive, reversed(l) non-destructive (copy)

    x = a + b + [1, 2] # concatenation (non-destructive)
        use a.extend() for destructive

    x == y # value equality implemented
    x = [0] * 100 # initialize with 100 0s

tuple
    x = (1, 2, 'hi')
    x = 1, 2, 'hi'
    # immutable!
    print(x[0])

    y = (1,)    # single value tuple syntax

    () = empty tuple

    and some of the stuff from list above

set
    x = {1, 2, 3} # mutable
    x.add(4)
    x.update([5, 6, 7]) # any iterable
    x.remove(7)  # raises error if not present
    x.discard(6)  # does not raise error if not present
    x.pop()   # remove and return arbitrary item
    x.clear()

    bitwise and minus operators overloaded to do set operations
    also set.intersection(s1, s2) static method
    also s1.intersection(s2) mutation

    NOTE: you cannot use {} as empty set because it's ambiguous with empty dict
        have to use set() constructor

    order is not guaranteed
dict
    x = {'a': 1, 'b': 2} # mutable
    x['c'] = 3
    # NOT ALLOWED: x.c = 3
    print(x['c'])  # raises KeyError if not present
    print(x.get('c', 0))   # default value if not present
    del x['c']
    x.pop('b')
    x.clear()
    x.setdefault(key, value) # set value only if not present

    default iteration and membership checks are for keys
    you can be more explicit: x.keys(), x.values(), x.items() which are tuples of key and value
        these are sequences, not lists or tuples (doesn't usually matter)

    empty dict = {} or dict()

    order (of either keys or values) is based on insertion order
collections.deque
    double-ended queue
    can serve as an efficient stack, queue, or linked list
        because it's backed by a linked list
    like Java's LinkedList, since you're behind an interface that forces O(n) indexing
        it's not as efficient as implementing your own for certain operations
    otherwise, it more or less looks like a list with some extra members
        where certain operations under the hood have different performance characteristics
    
    append() goes to right side in O(1)
    appendLeft() goes to left side in O(1)
    pop() comes off the right side in O(1)
    popLeft() comes off the left side in O(1)

    you can construct with a maxlen optionally
        means if you add on one side and it goes above that len, items will fall off the other side
Stack
    use list with append() and pop()
    can peek with l[-1]
    or use collections.deque
    list one is probably ok since not recopying whole array, just growing and shrinking
Queue
    use collections.deque because inserting at beginning is super costly
    similar to list but popleft() and popright()
    still use append()

bytes
    x = b'abc=xff' # char and hex values

Cloning
    x = [*y] makes a shallow copy of list y into x
    x = [**d] makes a shallow copy of dictionary d into x
    x = list(y) is another way to clone (like a copy constructor)
        often take an iterable rather than specific type
        so that you can also do conversions
    copy module also can deep copy
Conversions
    x = set(l) # list to set (to dedupe)
    x = list(set(l)) # list to list with deduping
Unpacking
    x, y, z = collection
        works for tuple, list, or other sequence
        as long as the length of the collection matches the # of variables
    [x, y, z] = collection
        means the same thing as above (regardless of whether list or tuple)    
Iteration
    for item in l:
        print(item)

    if an object is iterable, it will have an __iter__() method to return an iterator
    a generator function works as an iterator (supports the iterator interface)
    you can also make a class that has a __next__(self) method and return that
        python will call __next__() on the iterator as needed to get the next item
        it should raise StopIteration when there are no more items
    
    iterators can be directly used like this:
        it = iter(collection)
        while True:
            try:
                print(next(iter))
            except StopIteration:
                break
        
Membership
    if item in l:
        print('yes')

    all(item in small_list for item in l)
        a way to check if all items are in a collection
Comprehensions
    in general, look like the literal for the collection you're making
        with a for loop inside to generate the elements
    
    squared = [x**2 for x in nums]
    name_lengths = {name: len(name) for name in names}
    unique_vals = {x for x in nums}

    a special exception is with tuples and Generators
        gen = (x**2 for x in nums)
            this is a GENERATOR COMPREHENSION instead of TUPLE
        tup = tuple(x**2 for x in nums)
            this is a TUPLE COMPREHNSION (technically casting generator)

    nesting is done with 2 for loops inline
        [x**2 for row in matrix for x in row]
            this flattens the matrix and gets the squares of its elements as a flat list

    conditional comprehension with 'if'
        even_squares = [x**2 for x in nums if x % 2 == 0]

    generator comprehensions can also be used directly as function call params
        f(x**2 for x in range(10))
            f() will get called with 1 arg, the generator (which is iterable)

Negative indices
    -1 = last item, -2 = 2nd to last item, etc.
Slicing
    [2:5] # includes 2, 3, 4
    [:2] # includes 0, 1
    s[-2:] # includes last 2 items only
    s[:-1] # excludes last item
    s[start:stop:step] # full version (all 3 can be left off and/or negative)
        step -1 can be used to REVERSE the order
        but the start and stop are taken literally and might end up empty
        (ommiting start or stop is a special case where it will smartly adapt)
    you will get empty list for invalid range (not throw)

    for mutable collections, slices can be assigned
        eg. assign [] to clear that range
        eg. del operator on the slice to clear that range
        eg. assign a list to change that range (even on size mismatch)
    however, when stored as a variable, slices are COPIES of parts of the list
Ranges
    the range() function works similar to slicing
    it returns an iterable that you can use with a 'for' loop
Sorting
    sorted(l, key = fn, reverse = False)
        fn should return value to sort by (can be derived/transformed arbitrarily)
        ascending by default, can also reverse it for descending
        the sort key will be used for sorting using the < operator
            if the sort key is a custom class (or no sort key so elements used), then __lt__ will be called
    the rough java equivalent is:
        < operator = Comparable<T> implementation
        key = Comparator passed in to override that
    in general, if a collection or method doesn't take a reverse parameter, you can use a key like this to reverse the order:
        key = lambda x: -x
        key = operator.neg
Shuffling
    use random module
Searching
    bisect module has bisect_left and bisect_right to do binary search on sorted collection
    bisect_left(sorted, item) uses < operator to look for leftmost occurence (and get index)
    bisect_right(sorted, item) uses < operator to look for 1st item after rightmost occurence
        can use as exclusive upper bound if want to take whole range
    both let you pass in low and high bounds of the search as well as a key
    if the index returned is len(sorted), then the insertion point is at the end (and item is not found)
        or in the case of bisect_right, the item you wanted might be the last thing in the array (special case)
    otherwise, you can tell if it was found or not by doing == on sorted[index]
Objects as keys
    any of the built-in collections are hashable and thus can be used as keys
    your own classes can be hashable if you implement the right stuff too
Implementing Objects for Collections
    == operator is used for membership tests
    < operator is used for sorting and binary searching
    hash() is used for dict insertion
    hash() and == are used for dict retrieval
    repr() is used for printing collections (trickles down to elements)
    str() is used for converting collections to string (trickles down to elements)

Sorted containers (from 3rd party sortedcontainers library)
    (avialable in Leetcode for solving problems)
    SortedList
        acts like a list but keeps item in sorted order (duplicates allowed)
            O(logn) lookup both by index and by value (due to tree)
        you can retrieve items by index, but you cannot add them by index (even implicitly)
            eg. cannot do append() or extend() because they add to end
            eg. cannot do insert() or a[i] = val
            eg. can't do reverse() [but can do reversed()]
        like a normal list, it is iterable, can check membership, etc.
        SortedList(seq, key = None) constructor
            passing a key actually gives back SortedKeyList which is subclass
        < operator used for items
        bisect_left(val) and bisect_right(val) methods
    SortedKeyList
        a SortedList subclass that uses a custom key function
        adds bisect_key_left() and bisect_key_right() methods too
    SortedSet
        acts basically like a normal set, but when you iterate, the items are in sorted order
        < operator and/or key in c'tor
            hash() also used
    SortedDict
        acts basically like a normal dic, but when you iterate, the items are in sorted order (by keys)
        < operator and hash()
        uses SortedList internally, so methods like bisect_left(key)

Priority Queue/Heap
    the heapq module (built-in) provides a priority queue/minheap implementation
        but instead of a class/type, it is a set of functions that operate on normal lists
        if you wanted it to be a class, you could make a class to wrap it easily
    to use a custom class, you would implement the < operator as usual
    to make it a maxheap, you have to use a hack because there is no way to use a custom key
        eg. negate the value on push, then negate it again on pop
    
    start with [] (an empty normal list)
        or take a list with values and call heapify(l) to turn it into a heap (heap sort it)
    heappush(l, val) puts a value into the heap
    heappop(l) gets the smallest value from the heap and reduces its length by 1
    heappushpop(l, val) = push then pop
    heapreplace(l, val) = pop then push

Immutability
    list -> tuple
        independent copy
    set -> frozenset
        independent copy
    dict -> types.MappingProxyType
        view on the original

Thread Safety
    in general, read operations on collections are thread-safe, but write operations are not
        and read during write is not
    this applies to almost all the built-ins as well as sortedcontainers
        also applies to heapq
    one exception is collections.deque, which is designed to be thread-safe on the two ends
        but not in the middle
    to add thread safety, use locking

Swapping
    a,b = b,a # right side makes tuple, left side unpacks it

Not Available:
    persistent slice that responds to changes in original and/or can be used to modify the original
    a lot of the optimization methods in set and dictionary
    in-place compuatations on dicts
        which probably doesn't matter if using the O(1) version anyway
    built-in sorted dict and set (use sortedcontainers library)
    directly making maxheap (have to use a hack)
    special types for bitfields, bit sets, enum sets, enum maps, etc.
    string builder (see in Strings)
    case insensitivity in strings
    tree/graph directly by nodes (implement yourself easily with classes)
    struct/value type (though @dataclass and NamedTuple has that kind of goal)
    proxy pattern immutable wrappers
    proxy pattern synchronized wrappers

[Strings]
# for comments

'' and "" are same (and allow to use other unescaped)
''' and """ are multi-line strings
r'' and r"" are raw strings
f'' and f"" and f''' and f""" are f-strings

immutable (modifications return copy)
    you can get a mutable copy as a list of chars with list(s)
        make back into string with ''.join(c)

strip() to remove leading/trailing whitespace
    lstrip(), rstrip()
replace(old, new)
upper(), lower(), title()
split(delim) -> gets list of strings (similar logic to Java but not regex)
    split() -> split by whitespace
delim.join(l) -> join a list by a delim string (method of str)
startswith()
endswith()
isascii(), isnumeric(), isalpha(), isalnum(), isupper(), etc.

find(), rfind(), replace(a, b, count=None), removeprefix(possiblePrefix), removesuffix(possibleSuffix), 

s = s1 + " " + s2

if substring in s:   # substring search
    print('present')
s.index(substring)   # explicit search
s.count(substring)

formatted strings
    NOTE: with any of these, you can store the template as a variable in itself
        though in an f-string, that would already be evaluated
    
    f'Hi, my name is {name} and I am {age} years old.'
        name and age should be variables in the encosing scope
    'Hi, my name is %s and I am %d years old' % (name, age)
        this is the old-fashioned way, replaced by f-strings above
        for single value, no () needed
    'Hi, my name is {} and I am {} years old.'.format(name, age)
    'Hi, my name is {name} and I am {age} years old.'.format(name=name, age=age)

    {:.2f} (example of format specifier - in this case float with 2 places after decimal point)
        or in the old style %.2f
        see Java notes for rundown of the specifiers (%02d, %.2f, %15s, %-15s, %s, %d)
    format specifiers are pretty permissive about type mismatches

string as collection
    len(s)
    s[0], s[-1], s[1:3]
        none of these support assignment
        slicing gives another string
    for c in s:
        print(c)
    l = list(s)   # mutable copy as list of characters
    because str is iterable, things like sorted(s) will work too

    NOTE: character is not a type - it is just a string of length 1

string builder
    there is no StringBuilder-like class in Python
    the pythonic way to efficiently append to a string is to build a list and use ''.join() on the list
        could even use a list comprehension to do it all inline

conversions
    int(s) will throw ValueError if not a proper integer string
        isnumeric(s) can be used to check it first
    str(n) will use the __str__ method of the object (simple for types like int)
    repr(n) will use the __repr__ method (simple for types like int)
    print(n) will automatically use __repr__

regular expressions
    see 're' in 'stdlib' section

'string' package
    for getting list of ascii letters, punctuation, etc.

Encoding
    python strings (in python 3) are unicode (utf-8)
    to convert a string to bytes, use s.encode('utf-8')
    to go the other way, b.decode('utf-8')
    previous versions of python had a lot of complications about unicode but not anymore

Line endings
    the different system ones all becomes \n on read
    \n becomes proper system one on write
    there are params to customize it in open(), read(), write(), etc.

Case insensitivity
    not built-in like most languages
    commonly done by converting tolower() for comparison
    or use re.IGNORECASE with regex

Extra copies
    you can assume operations that take portions of strings make copies
        for same reason as Java - don't want to keep big one around for small one
    but it's possible under the hood some optimizations are done you don't know about

[Operators]
mostly the same as C-like languages with some exceptions
    additional operators like // and ** also support assignment (//= and **=) like others

missing
    ++ and --
    safe navigation
    coalescing
division
    // behaves like / in c-like languages (floor division)
    / becomes a float instead!
exponentiation
    a**b means a to the b power
boolean
    use words and, or, not instead of operators &&, ||, !
    eg. a and not b
bitwise
    unlike booleans, these use the usual symbols (&, ^, ~, >>, etc.)

presence in collection (boolean)
    a in somelist
    b not in somelist

equality
    a is b
        True if same numeric value or same reference
        same as == in Java
    a is not b
        opposite of a is b
    a == b
        value equality
        more like .equals() in Java
    a is None
        considered better than doing a == None

truthiness
    since types aren't bound, there is a lot of flexibility for checks on variables
    the following values are falsey in conditionals:
        None
        False
        not True
        0
        ''
        []
    the rest are truthy
    you can disambiguate None from [], for instance, using is None first
    operators like and, or, not make into true booleans first

ternary
    no ? : like in C-like languages
    instead it looks like:
        a if a > b else b

collections
    [1, 2] * 3
        [1, 2, 1, 2, 1, 2]
    [1, 2] + [3, 4]
        [1, 2, 3, 4]
    [*mylist]
        spread operator (in this case copying mylist)

del
    x = 5
    del x
    print(x)    # Error
    del x,y   # delete multiple

    l = [1, 2, 3]
    del l[1]  # l = [1, 3]
    l = [1, 2, 3]
    del l[1:] # l = [1]

    del mydict[key]

hasattr(obj, name) to see if an attribute exists on an object
    useful if you're going to be hiding variables in functions, for instance
    eg. hasattr(x, 'count')

[Control Flow]
; isn't required, but it is a way to fit multiple statements on one line
    eg. for shell one-liners

pass
    a noop statement
    eg. for an empty loop or function body (because required to have something there)

if a < b:
    print(a)
elif b < a:
    print(b)
else:
    print('same')

while a < b:
    a += 1
    print(a)

for element in l:
    print(element)

for index, element in enumerate(l):
    print(index, element)

for x, y in l:
    # each element of l is a tuple which is unwrapped here

for i in range(10):
    print(i) # 0, 1, 2...9

break and continue supported as usual

match term: # like switch in another language
    case 'bla1':
        print('bla1')  # no fall-through, so no break needed
    case 'bla2':
        print('bla2')
    case _:    # like default in another language
        print('default')

try:
    someCodeThatMightThrow()
    raise MyThrownException('I threw')
    print('this code is unreachable')
except ZeroDivisionError:
    print("division by zero!")
except MyThrownException as e:
    print("Error: " + str(e))
except (OtherError1, OtherError2) as e:
    print("Either OtherError1 or OtherError2" + str(e))
finally:
    print("this will run no matter what")

Exception is the usual common base of exceptions
    raise Exception('summary', 'details')
    e.args
    str(e)
    traceback.print_exc() [don't need to pass in e]
        gets callstack and prints to stderr
some built-in errors:
    Exception
        the most common base
    KeyError
        eg. dictionary doesn't have key
    ValueError
        eg. int() on a string that is not an integer
    AttributeError
        attribute (method or variable) not present on object
    StopIteration
    IndexError
        eg. subscript out of range
    ZeroDivisionError
    FileNotFoundError
    KeyboardInterrupt
        triggered by ctrl-c
    NotImplemented

with open('myfile.txt') as f: # context management
    contents = f.read()
print(contents) # notice contents variable still lives (as does f, but in a closed state)

with open('myfile.txt'):
    print('not necessary to keep variable - context is still active')
with open('myfile.txt') as f, open('myfile2.txt') as g:
    print('2 contexts at same time!')

asserts run as long as you don't run with -O (optimized) flag
    assert condition
    assert condition, message

[Functions]
def f(a, b, c):
    return a + b + c
x = f(10, 20, 30)

Overloading
    true overloading does not exist
    if you define the same name twice, the later one replaces the earlier one, even if params are different
    you have to simulate overloading with default args and keyword args
Tuples
    return (a, b)
        use tuple to return multiple values from a function
    a, b = f(x)
        tuple unwrapping in-place
Default args
    def f(x, a=0, b=0):
        pass
    f(10)
    f(10, 20)
    f(10, 20, 30)

    def f(a=g()):  # not a "compile-time constant"
        return a
Default Mutable args
    this is a weirdness of Python
    when a default value of an arg is a mutable type like a list or dictionary
        then modifying it within the function will modify the default (because it's cached that way)
    eg. def f(x, a=[]):
            a.append(x)
        # every call to f without an a arg will grow the default a arg
        # if you call with an a value, then call again without one, the cached one will come back
Keyword args
    using same f as "Default args" above
    f(10, b=1000, a=700)
    f(10, b=10)

    f(a=a)
        something you commonly see when delegating args
        Python knows the difference between the left and right side of this
Default return
    when a function doesn't have a return statement, or reaches the end without returning
    it returns None (which you can ignore to make it simulate void in other languages)

Spread (star and double-star)
    f(10, arg=100, *l, **k)
        l = positional args expanded in-place
        k = keyword args expanded in-place
        a way to forward variadic args
            in addition to using collections to store args
Rest/Variadic (star and double-star)
    def f(x, a=10, *args, **kwargs):
        pass
    args becomes a list of positional args passed in besides the named ones
    kwargs becomes a dictionary of keyword args passed in besides the named ones

Generators (lazy)
    def f():
        yield 1
        yield 2
    print(list(f())) # evaluate whole thing

    def g(seq):  # lazy sequence in terms of another lazy sequence
        for item in seq:
            yield item**2
    print(list(g(f())))

    def h():
        yield 0
        yield from f()  # expanded in-place (like * operator)
        yield 3

    def i():
        x1 = yield 0
        x2 = yield x1 * 10
        yield x2 * 20

    # two-way communication
    gen = i()
    next(gen) # 0
    gen.send(100)
    next(gen) # 1000
    gen.send(1000)  # x2 becomes None if you don't call this
    next(gen) # 10000
    next(gen) # raises StopIteration
    # you could use the gen.send() values to actually detect when to stop returning (eg. break a loop)

Extension Methods
    not directly supported, but easy to do
    just make a function that takes a self param first
    then assign to the class itself (or to an instance if you want)
        eg. MyClass.my_method = my_method
    then you can call it like any other method

recursion
    function calls itself by name
    no TCO

not supported: macros, inline, ref and out params

[Functional]
f = lambda: print('hi')
g = lambda x: x**2
h = lambda x, y=10, *args: x + y + max(args)
def myfunc(x):
    print(x)
x = myfunc
    a function name is just a variable assigned with a function object
    it can be reassigned and they both point to the same thing

f()
print(g(10))
print(h(10, 20, 30, 40))
x(10)

nested functions are allowed and can be used like lambdas too
    def f():
        def lam():
            print('hi')
        return lam
    f()()

    NOTE: this is the only way to do multi-statement lambdas in Python
        there is no way to have {} around a body like in other languages

ignored params: _, __, etc.
    you can use these in a function or a lambda as params
    they are technically real names and can be used as such
        but by convention, they are ignored params
        usually to make args match without losing readability
    eg. for _ in range(10):
            print('hi')   # print 10 times, don't need index
    eg. a, _ = f()  # unwrap without length error, but only need 1st thing

functional operations
    map
        seq = map(lam, l) # lazy sequence
        print(list(seq))

        NOTE: you can often do LIST COMPREHENSIONS instead
    reduce
        val = functools.reduce(lam, l, seed)
        print(val)
    filter
        seq = filter(lam, l)
        print(list(seq))

        NOTE: you can often do LIST COMPREHENSION with an 'if' inside

    zip
        multiple lists to list of tuples
            seq = zip(l1, l2, l3)  # variadic
            for i1, i2, i3 in seq:
                print(i1, i2, i3)
        list of tuples to multiple lists
            l1, l2, l3 = tuple(zip(*seq))
        parallel iteration
            for i, j in zip(is, js):
                print(i, j)

        NOTE: zip is lazy like the other functional operations
        
    all
        all(seq) = True if no elements are falsey (inc. if empty)
    any
        any(seq) = True if at least one element is truthy (false if empty)

    a lot of operations that are explicit calls in other languages are handled by Python syntax already
        groupBy, flatMap, etc. can be done just by COMPREHENSIONS
        limit and skip can be done by SLICING (but need to use islice if itertools sequence)

itertools
    see stdlib section below
    itertools lets you do various stream operations for declarative lazy sequence processing
    an alternative to writing your own generator comprehensions and such
        or along with it, such as this comprehension: (x**2 for x in itertools.repeat(10))

Closures
    python closes BY REFERENCE over variables by default
        for i in range(10):
          yield lambda: print(i)
        This will print 9 over and over (10 times)
            because i is captured by reference even though it's primitive!
            then the lambdas are returned all closing on the same variable that continues to live
        This happens with nested functions too, not just lambdas!
    in order to close BY VALUE instead, you need a lexical capture point (a function call)
        def make_lambda(x):
          return lambda: print(x)
        for i in range(10):
          yield make_lambda(i)
    the good part about this behavior is you can modify the state
        eg. increment a counter, iterate lines in a file, etc.
    just remember that when it's a parameter, it's by value and when it's implicitly captured, it's by reference

Class Method References
    m = MyClass()
    map(m.f, l)
        method f of class MyClass is BOUND to instance m
        map() will call it like a pure function, and m will automatically be passed as self
        NOTE: if you see lambda x: m.f(x), you can probably just replace that with m.f
    MyClass.f(m)
        method f of class MyClass is UNBOUND, so you have to pass an instance as the first arg
    you can treat a class itself (or a variable referencing it) as a callable function for construction
        constructor = MyClass
        m = constructor(10)
Operator Module
    functions like add, mul, neg, lt, etc.
    so that you can treat operators functionally too
Commonly Used Method References to Replace lambdas
    str.lower
    list.append
    int
    len
    sum
    operator.add, operator.mul, etc.

Chess Queen Attacks: see Java notes (ToDo: move into common place)

IIFE
    (lambda x: x**2)(5)

not supported:
  - pre-defined function types (for type hints only can use Callable)
  - special findfirst and findany calls

[Classes]
like with functions, a class object can be assigned to variables and still act as the class
    eg. OtherClass = MyClass
        o = OtherClass()

'self'
    similar to how you have to put 'this' everywhere in JS, you need 'self' to access instance members
    in addition, you have to explicitly pass 'self' as the first param of instance methods!
Inheritance
    uses a prototype-like inheritance (similar to JS)(but no prototype member)
        if an attribute (either variable or method) is directly set on an instance, that is used
            allowing you to add and replace functions and variables at runtime
        if it is not directly set, it is forwarded to the class
            the (technically) class/static members are then returned/used
        if not set on the class, then the base classes (from left-to-right) are checked in DFS order
            if not found in the hierarchy at all, then AttributeError is thrown
    a key thing to note here is that instances dynamically see changes to their classes
        it is not clone stamped at the point of instantiation
        but changing superclass won't affect instance if subclass defines that symbol
    no 'virtual' keyword - everything is virtual (like Java) due to how the lookups work
        just using the same name overrides already
        both for variables and functions
    static methods act this way as well
        the difference is that they don't have to have self as the first param
    also note that everything is by name only, not by args or type
        because no overloading in python

    diamond inheritance
        ambiguity resolved by taking first thing from left in class's inheritance list (MRO)
        a result of how attribute lookups work

    unlike other languages, base c'tor is only automatically called if derived class has no c'tor!
        can explicitly call it like below though
object
    the root of the type system is called 'object'
    even primitives inherit from object
    the default hash function returns a different hash for each instance
        which makes it useful for unique opaque dictionary keys and such
    object can be directly instantiated too
        eg. to use as opaque key or something
Access Modifiers
    apply within classes as well as top-level things in modules
    default = public
    _ = protected (or semi-private)
        only by convention (not enforced)
    __ = private
        enforced by NAME MANGLING at runtime
            though the mangling is predictable and defeatable
    __somename__ = not an access modifier but a special value with special meaning

    the "we are all robots" case (instances accessing each others' private variables) works here

class MyClass:
    static_var = 10
    other_var = static_var  # no self needed because not in a method

    def __init__(self, instance_param):
        self.instance_var = instance_param

    def f(self, x):
        print(x)
        print(self.instance_var)

class MyDerivedClass(MyClass):
    def __init__(self, instance_param):
        super().__init__(instance_param)
        self.derived_var = 10

    def f(self, x):
        print('inherited!')
        print(x)

    @staticmethod   # special attribute for static method
    def g(x):       # no self needed for static
        print(x)

    @classmethod
    def h(cls):     # class passed as arg
        print(cls.static_var)

class MultipleDerivedClass(BaseClass1, BaseClass2):   # no restriction
    pass

m = MyClass(x)  # self passed implicitly (no 'new' keyword)
print(m.static_var)  # this is actually a copy now
print(MyClass.static_var)
print(m.instance_var)
m.f(100)

MyDerivedClass.g(100)
MyDerviedClass.h()

Interfaces
    python doesn't have interfaces - everything is duck-typed
    as long as the things referenced or called by the caller are on the object, it works
    you could throw NotImplemented from a method to make it "abstract"

Abstract Base Class
    you could just have methods throw NotImplemented to make an ABC
    there is also an abc module to make it a little more automatic (but not much)
    hooks into the internals of the class to make it act like a language feature
    see details in [stdlib]

Special Class Members
    certain members can be present on your class to implement certain behaviors in python

    __init__(self, ...) = c'tor
    __del__(self) = d'tor

    __str__(self) = converting object to string
        eg. str(m)
    __repr__(self) = string representation for debugging
        eg. print(m)

    __len__(self) = length of the collection
    __iter__(self) = iterator class or generator function for iterating elements
    __contains__(self, item) = membership check

    __getitem__(self, index) = index operator (index could be anything you want)
    __setitem__(self, index, value) = setting value by index
    __delitem__(self, index) = deletion of value by index

    __getattr__(self, name) = for reading values from an instance with . operator (as if fields)
    __setattr__(self, name, value) = for dealing with assignment via .
    __delattr__(self, name) = for deleting with deleting attributes via .

    __getattribute(self, name)__ = generic attribution retrieval

    __call__(self, ...) = call operator - for calling object as if it is a function
    __enter__ and __exit__ for context management

    __eq__(self, other), __lt__(self, other), __add__(self, other), __sub__(self, other), __and__(self, other), etc.
        implementations for operators like ==, <, +, -, etc.
    __bool__(self), __int__(self), etc. for type conversions
    __hash__(self) = for hashing (eg. in dict)
        if object has multiple fields, make them a tuple and hash that
        eg. return hash((self.field1, self.field2))

    NOTE: a lot of these methods have top-level functions without underscores you can call to invoke them conveniently
        eg. instead of m.__hash__(), you can call hash(m)
        eg. hash(), str(), len(), iter(), etc.

    even more advanced ones like __new__ to hook construction and do crazy things

Constructors
    there is only one method of each name due to lack of overloading in Python
    so if you provide multiple __init__, only the last one will stick
        the others will be uncallable
    thus, there are no delegating constructors within same class
    if you don't provide __init__, then the object can be instantiated with no args

Properties
    class Circle:
        def __init__(self, radius):
            self.radius = radius

        @property
        def diameter(self):
            return 2 * self.radius

        @diameter.setter
        def diameter(self, value):
            self.radius = value / 2

        @property
        def area(self):
            return 3.14159 * self.radius**2

    circle = Circle(1)
    print(circle.diameter)
    circle.diameter = 4
    print(circle.diameter)
    print(circle.area)

Dataclass
    (for simple POD types)

    from dataclasses import dataclass

    @dataclass
    class MyClass:
        x: int  # required constructor arg
        y = 20  # optional constructor arg

        def f(self):
            return self.x + self.y

        # __init__ defined for you
        # has the member fields in order
        # ones with values are optional

    m = MyClass(10)
    print(m.f())

nesting
    clases, functions, etc.  can be nested inside each other w/ no issue
    nested classes don't inheritently have access to each others' private data
    you can define a class inside a function and return an instance of it
        this is a way to do anonymous classes

not supported: partial classes, friend classes (can use _ variables), sealed/final

[Generics]
because python is dynamically weakly typed and duck-typed, it does not have generics
any collection is a generic, with no constraints at all on elements (can mix and match however)
however, you can somewhat simulate it at least in type hints using Typing.TypeVar (for type checking purposes only)

[Imports/Exports/Modules]
import os
import sys
print(os.path)

import os, sys
print(os.path)

import os as operating_system, sys as system
print(operation_system.path)

from os import path
# avoid having to always use fully-qualified path
# works for module as well as symbols within module
print(path)

from os import path as os_path
# this works for renaming modules as well as symbols inside modules
print(os_path)

from os import *
# import all symbols (usually not recommended)

anything can be at the top-level of a module (variables, classes, functions, etc.)

python3 myfolder/myfile.py
    direct execution
    search path not used
python3 -m myfolder.myfile
    module execution
    search path used
        each . is a subfolder, but the root can be anywhere in search path
        this allows you to execute libraries and installed dependencies this way too
        current working directory, PYTHONPATH variable, installed packages, etc.
python3 -c 'import myfolder.myfile'
    execution via import (within one-liner shell command)
python3 -c 'from myfolder import myfile; print(myfile)'
    multiple statements within 1 line

__name__
    '__main__' for direct execution or module execution
    name of the module itself if executed via an 'import' instead
        either via -c or via executing another  .py file

    very common to see if __name__ == '__main__' at top-level to distinguish library vs. script execution
        eg. could run unit tests for script version

__file__
    path of the .py file (the current one, not the top level one)

sys.argv[0]
    the top-level thing being executed (instead of current file)
    for direct and module, it is the current file, but for imports, it's the thing executing at the top
    for one-liners that import the file, it's just -C
sys.argv[1:]
    args to the top-level script (passed to python3)
    things like --flag are passed exactly like that as 1 arg
    things like -n 5 are passed as 2 args exactly like that one after the other
argparse built-in library can help parse the arguments
common pattern in pip packages to have a dictionary of command name to function to call
    then use 1st arg as command and forward args to the function with * operator

package
    if a folder has an __init__.py file, it is a package
    a package will import subpackages (usually relative with . and ..)
        eg. from .deepsubfolder import deepmodule
            then it's available as mypackage.deepmodule to the caller
    packages can be in a hierarchy of other packages
    importing from subfolders directly won't work - you have to import the package and let __init__.py set it up

name clash issue
    if you name a file the same as an api you're calling, it will try to import itself
    the symptom of this will be that the import is empty
    another place this comes up is if a folder is named after a script (causing ambiguity)

[stdlib]                            
print(x)
print(x, y, z)
    print 3 values with space in between on single line
print() for newline only
print(x, y, z, sep='\t', end='')
    overriding sep and end
    in this case, tab between x, y, and z, and no newline at end
print("x:", x)
escape sequences for color (have to escape back again)
    alternatively, use a library like termcolor
print('text', file=sys.stdout)  # can choose what file to print to (default is stdout)
    can use sys.stderr also

text = input('Please enter a number: ')
    prompts user and reads what they enter (until and excluding the newline)
    you can loop for input if you want, and use a combination of a user entered value and KeyboardInterrupt (ctrl-c) to break
num = int(text.strip())
    example of reading numeric value
vals = [int(item) for item in input('Please enter numbers: ').strip().split()]
    example of reading structured input

open() for file I/o doesn't need an import
    with open(path, 'r') as file:  # open for text read
        for line in file:          # iterate lines (inc. newlines)
            print(line.strip())    # strip whitespace
        
        lines = file.readlines()   # list of lines (inc. newlines)

        content = file.read()      # read whole file as single string
other open modes include:
    w = write (use write() method which does not write a newline) (use \n)
    a = append
    b = binary (bytes instead of str)
    eg. 'wa', 'wb', 'rb', etc.

math
    isnan(x)
    isclose(x, y)
        for float near-equality
    sqrt(x)
    floor(x)
    exp(x) [e to the x]
    log(x) [natural log]
    log(x, base)
    radians(angle)
    cos(radians)
    pi = constant
    e = constant
operator: functions for passing operators around functionally
    add
    mul
    not
    lt, gt, eq
    neg
    truth
    is
    abs
    getitem, setitem
statistics
    mean(l)
random
    seed(value)
    randint(inclusiveLower, exclusiveUpper)
    random() [float from 0 to 1, not including 1]
    shuffle(l) [destructive]
    gauss(mean, stddev)

    Random() to make an independent random number generator instance
        call with methods like the above
        eg. to put on thread-local storage

bisect
    bisect_left(sorted, element)
    bisect_right(sorted, element)

functools
    reduce() [but map and filter are in global/default namespace]

itertools
    chain(seq1, seq2)
        concatenates multiple sequences lazily into one sequence
    cycle(seq)
        lazily repeats a sequence forever
    repeat(val, n)
        lazily repeats a value n times
    repeat(val)
        infinite lazy sequence
    count(start)
        infinite lazy sequence of consecutive integers
    count(start, step)
        same but with a step other than 1
    combinations(seq, length)
        all combinations of 'length' elements of seq 
            only unique combinations, with same element not being paired with itself
    permutations(seq)
        all possible permutations of sequence
    dropwhile(lam, l)
    takewhile(lam, l)

    the values returned by these are iterable sequences, but not indexable/slicable
        you can use islice() to lazily slice them

    islice(seq, count)
    islice(seq, start, stop)
    islice(seq, start, stop, step)

collections
    defaultdict: dictionary with default values for keys not present
        d = defaultdict(int)  # specify the type in c'tor
        print(d['notpresent']) # 0
        d['notpresent'] += 1 # becomes 1
        trying to get or set the key makes it present from then on
    Counter: count dictionary
        counts = Counter([1, 1, 2, 3, 3, 3, 4])
        print(counts[1])  # 2 because there are 2 1s
        print(counts[0])  # 0 because not present
        print(counts.most_common(2)) # [(3, 3), (1, 2)]
        print(counts.most_common(1)[0][0]) # 3
        print(sum(counts.values()))  # total count
    namedtuple: tuple with named fields (like a struct)
        acts like a normal tuple and a class at same time

        Point = namedtuple('Point', ['x', 'y'])
            give the internal names of the class to create and the fields
                all as strings
            pass a 'defaults' keyword arg with a list to provide default values
        p = Point(10, y=100)
            takes positional and keyword args

        p[0]
        x,y = p
        p.x
        p.y

    deque: double-ended queue
        more efficient than regular lists for stack and queue operations

    abc (abstract base classes)
        Callable = type annotation for a fn
        Sequence = type annotation for a generic sequence
heapq
    heapify()
    heappush()
    heappop()
    heappushpop()
    heapreplace()

abc: abstract base classes
    ABC: inherit from this to make the class not instantiable directly
    @abstractmethod: mark methods that subclasses must override
        if a class inherits your class and overrides all these, it is concrete

os
    path
        expanduser('~/subfolder') -> '/home/username/subfolder' for instance
        abspath(path)
        relpath(abspath, relativeToPath)
        dirname(path) -> parent folder of file or folder
        basename(path) -> remove extension if present
        splitext(path) -> split into basename and extension parts
        join()
        exists()
        isfile()
        isdir()
    walk(path)
        pre-order DFS (alphabetical) of folder tree starting at root
        iterable of tuples of 3 items so you can do this
            for dirpath, subdirnames, filenames in os.walk('.'):
              print(dirpath, subdirnames, filenames)
        paths are made to look like what you passed in (relative of absolute)
        what you see in subdirnames, you are about to go into on a future iteration
            but the current iteration is your chance to deal with the files themselves
    listdir()
        list files and folder (by name) in current working directory (or given directory)
    getcwd()
    chdir()
    mkdir()
    makedirs() [to make multiple levels]
    rmdir() [must be empty]
    environ = dictionary of environment variables (no $)
        can be used to get/set in current shell instance
    getenv(varname, default)
    putenv(varname, value)

shutil = higher-level OS file system functionality than os
    copy()
    move()
    rmtree() [doesn't require empty]
    make_archive() [to make zip file]
    unpack_archive() [to unzip]

sys
    stdout
    stderr
    stdin

    argv = list of cmdline args (element 0 = the top-level call such as the python file)
    exit(code) = exit whole program with exit code
    stdin, stdout, stderr
    path = module search path (list of strings)
        can append to it to add to the search path dynamically before importing a module
    platform = OS info
    version = Python version
    modules = currently imported modules

glob
    glob('**/*.py')
        recursive list of all python files in all subfolders in current working directory

traceback
    print_exc()

re
    use rawstrings to delimiante one level of \
    methods tend to take a regex string first
        because you can use re.compile(regex) to compile
        then methods on the compiled regex will look the same but drop first arg
            technically just calling them as instance instead of static
    
    named capture groups look like this in python: "(?P<name>text)

    sub(regex, replacement, text) -> returns new text with all replacements made
        can refer to capture groups as \1, \2, etc. (or \g<1>, \g<2>, etc.)
        can refer to named capture gruops as \g<name>
        both of these differ from other languages where you use $
    findall(regex, text) -> list of all substrings matching
        if regex has capture groups, you get a tuple of capture group texts for each match instead
    finditer(regex, text) -> like findall, but more info
        match.group(numOrName) to get capture groups

    compile(regex) -> can call the methods above without first arg
        pre-compiled for efficiency on multiple texts

    modifiers like re.MULTILINE go as last arg in compiling or in method calls
        re.MULTILINE = treat ^ and $ as per line
        re.DOTALL = include newlines in .
        re.IGNORECASE = case insensitivity
        combine with bitwise | operator

    ** see Regex Syntax spreadsheet **
string
    ascii_letters = collection of all ascii letters
    punctuation = collection of all punctuation chars

pickle: read and write objects as binary file content
    dump(obj, file)
    load(file)

    file must be open with open() as usual
    depends on __getstate__ and __setstate__ members of object
        the built-in stuff has it already

copy
    deepcopy(obj)
        depends on __copy__ and __deepcopy__ existing on object (as built-ins have)

time
    deals with seconds (as floats)

    time() # since epoch
    perf_count() # higher-precision, less range
    sleep(time)
    localtime() # struct of time information fields

datetime
    time(hours, minutes)
    datetime.now()
    date.today()
    timedelta(days=1)
        total_seconds()
    datetime.now() + timedelta(days=1)

asyncio
    lets you do async/await type stuff just by importing it (without having to reference)

    async def f():
        return 10

    async def g():
        x = await f()
        return x

    val = asyncio.run(g)  # top-level, once per program, to kick off the async graph
    print(val)

    see also: async with, asyncio.gather(), asyncio.Lock (async/await friendly alternative to threading.Lock)

argparse
    parser = argparse.ArgumentParser()
    parser.add_argument(...) to add each arg and info about it one by one
    args = parser.parse_args()
    args.field1, args.flag, etc. then available

dataclasses
    dataclass: decorator for defining a data class

logging
    basicConfig()
    logger = getLogger()
    logger.info('this is an info message')
    logger.error('this is an error!')

importlib
    reload(module): to reload a module (eg. to test changes)
        reloads all references to same module even if imported multiple times in different ways
    
typing
    Any
    TypeVar
    Union
    Optional

types: dynamic type creation stuff
    MappingProxyType: read-only view of a mapping with [] operator (such as dictionary)

enum
    Enum
    auto

threading
    multiple threads in python do not run concurrently because of Global Interpreter Lock (GIL)
        but can be preempted at any time to run a different one
        inc. in the middle of print statements
        good for IO-bound tasks, not for CPU-bound
    timeouts are in float seconds

    Thread
        thread = Thread(target=fn, args=(arg1,)) # can ommit args
        thread.start()
        thread.join(timeout) # optional, can wait forever too
        thread.is_alive()
            thread can die by normal termination or an exception

        the OOP version is to inherit from Thread and implement run() method

        no way to force kill threads
        main thread ending doesn't end other threads (even with sys.exit())

    Event
        e = Event()
        pass e to threads (eg. as arg) and also use it in parent
        e.set() to signal event
        e.wait() to wait for event (with optional timeout)
        set will wake up all waiting threads (not just 1 like a condition)

        this is the cleanest way to stop a running thread from another thread

    Lock
        l = Lock()
        pass l to threads (eg. as arg) and also use it in parent
        with l:
            # this is a critical section
        not reentrant!
        no special syntax keyword

    RLock
        exactly like Lock, but it's reentrant
    Semaphore
        exactly like Lock, but c'tor takes a count

    Condition
        acts as both a lock and an event
        but with wait(),notify(),notifyAll() like in Java
        you wait or notify within a critical section, unlike with events

    Timer
        thread = Timer(delay, fn)
        thread.start()

    Thread-local storage
        thread_local_storage = local()
            can call this globally in the main thread
            each thread will have its own copy
        thread can add and retrieve attributes from the thread_local_storage object
            eg. thread_local_storage.random = random.Random()
    
    ** no volatile keyword needed **
    ** no atomic types available **

multiprocessing
    uses parallel processes with IPC
        separate address spaces, copied from host process on creation (kind of)
        benefit = get around GIL and achieve true cpu-bound parallelism
        drawback = extra overhead and have to use IPC because no shared memory

    Process
        process = Process(target=fn, args=(arg1,))
        process.start()
        process.join()

    Pipe
        parent_conn, child_conn = Pipe()
            pass child_conn into child process via args
        child_conn.send()
        child_conn.close()
        parent_conn.recv()
        ** there is also a bi-directional version**
    Queue
        use same object in parent and child process
        put() and get()
    Value
        use same object in parent and child process
        'value' attribute (read and write) to share a data value
    Array
        use same object in parent and child process
        read/write via indexing/slicing to share data
    Manager
        for more complex objects and flexibility

concurrent.futures
    thread pools, executors, and futures all tied together

    ThreadPoolExecutor
        executor = ThreadPoolExecutor(max_workers=n)
            threads are created only as needed, so can set high
            set to 1 for single thread executor
        future = executor.submit(fn)

        future.done() boolean
        future.result() to block on and get value

        future.cancel() to request cancellation
            only works if didn't start yet

        executor.shutdown(wait=True)
            wait for tasks to stop
            doesn't forcefully stop them (no way to do that)

        futures executing in the thread pool can use the normal threading stuff
            locks, conditions, events, etc.

        asyncio.wrap_future(future) can be used to combine futures w/ asyncio async/await
            can await the result of this

    ProcessPoolExecutor
        works similarly to ThreadPoolExecutor
        but uses multiprocess instead of threads
            which means have to use IPC to communicate

[pip]
** for any interactive command, use -y or -n switch to make it non-interactive**

pip install termcolor
    install package and make importable
pip install --upgrade termcolor
    install or update package
pip install termcolor==2.3.0
    install specific version
    downgrades if necessary
pip install 'termcolor>=1.1,<1.2'
    install from a range of versions

pip show termcolor
    print info about installed package
pip uninstall termcolor
    uninstall a package

pip list
    show installed packages
pip list --outdated
    show list of outdated packages

wheel = pre-built binary package for python
    can be installed via pip
    see Modules notebook for more details about wheels when needed (esp. the Apple and TensorFlow stuff)

[conda]
conda update conda
conda env list
conda create -y -n conda-demo python=3.11
conda activate conda-demo
conda deactivate
conda install termcolor
conda env export >env.yaml
conda env remove -y -n conda-demo

conda manages:
    python version
    pip packages
conda does not manage:
    working directory
    apt packages
    node packages
conda manages things by messing with PATH as you activate and deactivate environments

[3rd party libraries]
termcolor
    from termcolor import colored
    print(colored('hi', 'red', attrs=['bold']) + ' there')
    colored() just makes text with escapes inside which can be concatted with un-colored text
sortedcontainers
    SortedList
    SortedKeyList
    SortedSet
    SortedDictionary

[decorators]
function or callable class that wraps a function or class
    either returns it with some change, or returns another one wrapping it
eg. add attribute to function
eg. wrap a function in another function that does logging

def mydecorator(fn):
    def wrapper(*args, **kwargs):
        print('called')
        return fn(*args, **kwargs)
    return wrapper

@mydecorator
def myfn(x):
    return x**2

myfn(10)
    returns 100 and also prints 'called' because of the decorator
    myfn gets replaced by the decorator version right away

built-in decorators:
    @property: lets you treat a method as an attribute
    @staticmethod
    @classmethod
    @abstractmethod

[docstring]
""" multi-line strings in certain places
top of module for module documentation
top of function (below prototype - indented) for function docstring
top of class (below name - indented) for class docstring
after variable (eg. a constant)
can be one-line (all in one line) or have a space between the headline and the longer description

[type hints]
type hints aren't part of the actual execution of the program
    just for type checkers if you have one setup
    they can be arbitrarily left out, applied inconsistently, even wrong (if the type checker isn't aggressive or not set up)
the syntax is very similar to TypeScript

def add_numbers(a: int, b: int) -> int:
    return a + b

def print_this(a: int) -> None:
    print(a)

def do_stuff(a: int = 10, b: int = 5) -> int:
    return a + b

def add_numbers_list(l: list[int]) -> int:
    return sum(l)

def add_numbers_dictionary(d: dict[str, int]) -> int:
    return sum(d.values())

# This will still technically work if you pass <3 or >3 args.
def add_numbers_tuple(t: tuple[int, int, int]) -> int:
    return sum(t)

# aliases
Point = tuple[float, float, float]
Points = list[Point]

def centroid(p: Points) -> Point:
    return tuple(mean(axis) for axis in tuple(zip(*p)))

# variables
x: int = 5
y: Any = f() # any type (must be imported from Typing)

# collections.abc imports
# Callable (for functions)
def transform(list1: list[int], list2: list[int],
              fn: Callable[[int, int], int]) -> list[int]:
    return [fn(left, right) for left, right in zip(list1, list2)]
# Sequence (for sequences where you don't know if list, tuple, etc.)
def add_numbers(s: Sequence[int]) -> int:
    return sum(s)

# Generics (simulated)
from typing import TypeVar

T = TypeVar('T')

def first_thing(s: Sequence[T]) -> T:
    return s[0]

# Type union (shorthand for typing.Union[])
def make_str(a: int | str) -> str:
    if isinstance(a, int):
        return str(a)
    return a

# shorthand for typing.Optional[]
def coalesce(a: int | None) -> int:
    if a is None:
        return 0
    return a

[unit tests]
** see Unit Tests notebook **
not going to show much of it here
it works much like JUnit type stuff from other languages
class is instantiated to run test method
setup and teardown, etc.
mocking, faking, etc. available

[Jupyter]
throughout the notebooks, there are examples of jupyter usage
I did not include those here for now

[ToDo]
??or, and return value not boolean?
??varaible declaration only with no value in class?  (via type annotation, or without?)(dataclass at least does it)
??functools.partial
??functools members
??itertools members
??chess queen attacks into common place
